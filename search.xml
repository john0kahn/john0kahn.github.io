<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>TiDB FAQ</title>
      <link href="/2020/04/13/TiDB/"/>
      <url>/2020/04/13/TiDB/</url>
      
        <content type="html"><![CDATA[<h1 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h1><h2 id="一、-TiDB-介绍、架构、原理"><a href="#一、-TiDB-介绍、架构、原理" class="headerlink" title="一、 TiDB 介绍、架构、原理"></a>一、 TiDB 介绍、架构、原理</h2><h3 id="1-1-TiDB-介绍及整体架构"><a href="#1-1-TiDB-介绍及整体架构" class="headerlink" title="1.1 TiDB 介绍及整体架构"></a>1.1 TiDB 介绍及整体架构</h3><h4 id="1-1-1-TiDB-整体架构"><a href="#1-1-1-TiDB-整体架构" class="headerlink" title="1.1.1 TiDB 整体架构"></a>1.1.1 TiDB 整体架构</h4><p><a href="/overview.md#tidb-简介">TiDB 简介</a></p><h4 id="1-1-2-TiDB-是什么？"><a href="#1-1-2-TiDB-是什么？" class="headerlink" title="1.1.2 TiDB 是什么？"></a>1.1.2 TiDB 是什么？</h4><p>TiDB 是一个分布式 NewSQL 数据库。它支持水平弹性扩展、ACID 事务、标准 SQL、MySQL 语法和 MySQL 协议，具有数据强一致的高可用特性，是一个不仅适合 OLTP 场景还适合 OLAP 场景的混合数据库。</p><h4 id="1-1-3-TiDB-是基于-MySQL-开发的吗？"><a href="#1-1-3-TiDB-是基于-MySQL-开发的吗？" class="headerlink" title="1.1.3 TiDB 是基于 MySQL 开发的吗？"></a>1.1.3 TiDB 是基于 MySQL 开发的吗？</h4><p>不是，虽然 TiDB 支持 MySQL 语法和协议，但是 TiDB 是由 PingCAP 团队完全自主开发的产品。</p><h4 id="1-1-4-TiDB、TiKV、Placement-Driver-PD-主要作用？"><a href="#1-1-4-TiDB、TiKV、Placement-Driver-PD-主要作用？" class="headerlink" title="1.1.4 TiDB、TiKV、Placement Driver (PD)  主要作用？"></a>1.1.4 TiDB、TiKV、Placement Driver (PD)  主要作用？</h4><ul><li>TiDB 是 Server 计算层，主要负责 SQL 的解析、制定查询计划、生成执行器。</li><li>TiKV 是分布式 Key-Value 存储引擎，用来存储真正的数据，简而言之，TiKV 是 TiDB 的存储引擎。</li><li>PD 是 TiDB 集群的管理组件，负责存储 TiKV 的元数据，同时也负责分配时间戳以及对 TiKV 做负载均衡调度。</li></ul><h4 id="1-1-5-TiDB-易用性如何？"><a href="#1-1-5-TiDB-易用性如何？" class="headerlink" title="1.1.5 TiDB 易用性如何？"></a>1.1.5 TiDB 易用性如何？</h4><p>TiDB 使用起来很简单，可以将 TiDB 集群当成 MySQL 来用，你可以将 TiDB 用在任何以 MySQL 作为后台存储服务的应用中，并且基本上不需要修改应用代码，同时你可以用大部分流行的 MySQL 管理工具来管理 TiDB。</p><h4 id="1-1-6-TiDB-和-MySQL-兼容性如何？"><a href="#1-1-6-TiDB-和-MySQL-兼容性如何？" class="headerlink" title="1.1.6 TiDB 和 MySQL 兼容性如何？"></a>1.1.6 TiDB 和 MySQL 兼容性如何？</h4><p>TiDB 目前还不支持触发器、存储过程、自定义函数、外键，除此之外，TiDB 支持绝大部分 MySQL 5.7 的语法。</p><p>详情参见<a href="/reference/mysql-compatibility.md">与 MySQL 兼容性对比</a>。</p><h4 id="1-1-7-TiDB-具备高可用的特性吗？"><a href="#1-1-7-TiDB-具备高可用的特性吗？" class="headerlink" title="1.1.7 TiDB 具备高可用的特性吗？"></a>1.1.7 TiDB 具备高可用的特性吗？</h4><p>TiDB 天然具备高可用特性，TiDB、TiKV、PD 这三个组件都能容忍部分实例失效，不影响整个集群的可用性。具体见 <a href="/key-features.md#高可用">TiDB 高可用性</a>。</p><h4 id="1-1-8-TiDB-数据是强一致的吗？"><a href="#1-1-8-TiDB-数据是强一致的吗？" class="headerlink" title="1.1.8 TiDB 数据是强一致的吗？"></a>1.1.8 TiDB 数据是强一致的吗？</h4><p>TiDB 实现了快照隔离 (Snapshot Isolation) 级别的一致性。为与 MySQL 保持一致，又称其为“可重复读”。通过使用 <a href="https://raft.github.io/" target="_blank" rel="noopener">Raft 一致性算法</a>，数据在各 TiKV 节点间复制为多副本，以确保某个节点挂掉时数据的安全性。</p><p>在底层，TiKV 使用复制日志 + 状态机 (State Machine) 的模型来复制数据。对于写入请求，数据被写入 Leader，然后 Leader 以日志的形式将命令复制到它的 Follower 中。当集群中的大多数节点收到此日志时，日志会被提交，状态机会相应作出变更。</p><h4 id="1-1-9-TiDB-支持分布式事务吗？"><a href="#1-1-9-TiDB-支持分布式事务吗？" class="headerlink" title="1.1.9 TiDB 支持分布式事务吗？"></a>1.1.9 TiDB 支持分布式事务吗？</h4><p>支持。无论是一个地方的几个节点，还是<a href="/how-to/deploy/geographic-redundancy/overview.md">跨多个数据中心的多个节点</a>，TiDB 均支持 ACID 分布式事务。</p><p>TiDB 事务模型灵感源自 Google Percolator 模型，主体是一个两阶段提交协议，并进行了一些实用的优化。该模型依赖于一个时间戳分配器，为每个事务分配单调递增的时间戳，这样就检测到事务冲突。在 TiDB 集群中，<a href="/architecture.md#pd-server">PD</a> 承担时间戳分配器的角色。</p><h4 id="1-1-10-TiDB-支持哪些编程语言？"><a href="#1-1-10-TiDB-支持哪些编程语言？" class="headerlink" title="1.1.10 TiDB 支持哪些编程语言？"></a>1.1.10 TiDB 支持哪些编程语言？</h4><p>只要支持 MySQL Client/Driver 的编程语言，都可以直接使用 TiDB。</p><h4 id="1-1-11-TiDB-是否支持其他存储引擎？"><a href="#1-1-11-TiDB-是否支持其他存储引擎？" class="headerlink" title="1.1.11 TiDB 是否支持其他存储引擎？"></a>1.1.11 TiDB 是否支持其他存储引擎？</h4><p>是的，除了 TiKV 之外，TiDB 还支持一些流行的单机存储引擎，比如 GolevelDB、RocksDB、BoltDB 等。如果一个存储引擎是支持事务的 KV 引擎，并且能提供一个满足 TiDB 接口要求的 Client，即可接入 TiDB。</p><h4 id="1-1-12-官方有没有三中心跨机房多活部署的推荐方案？"><a href="#1-1-12-官方有没有三中心跨机房多活部署的推荐方案？" class="headerlink" title="1.1.12 官方有没有三中心跨机房多活部署的推荐方案？"></a>1.1.12 官方有没有三中心跨机房多活部署的推荐方案？</h4><p>从 TiDB 架构来讲，支持真正意义上的跨中心异地多活，从操作层面讲，依赖数据中心之间的网络延迟和稳定性，一般建议延迟在 5ms 以下，目前我们已经有相似客户方案，具体请咨询官方 <a href="mailto:info@pingcap.com">info@pingcap.com</a>。</p><h4 id="1-1-13-除了官方文档，有没有其他-TiDB-知识获取途径？"><a href="#1-1-13-除了官方文档，有没有其他-TiDB-知识获取途径？" class="headerlink" title="1.1.13 除了官方文档，有没有其他 TiDB 知识获取途径？"></a>1.1.13 除了官方文档，有没有其他 TiDB 知识获取途径？</h4><p>目前<a href="/overview.md#tidb-简介">官方文档</a>是获取 TiDB 相关知识最主要、最及时的发布途径。除此之外，我们也有一些技术沟通群，如有需求可发邮件至 <a href="mailto:info@pingcap.com">info@pingcap.com</a> 获取。</p><h4 id="1-1-14-TiDB-对哪些-MySQL-variables-兼容？"><a href="#1-1-14-TiDB-对哪些-MySQL-variables-兼容？" class="headerlink" title="1.1.14 TiDB 对哪些 MySQL variables 兼容？"></a>1.1.14 TiDB 对哪些 MySQL variables 兼容？</h4><p>详细可参考<a href="/reference/configuration/tidb-server/mysql-variables.md">系统变量</a>。</p><h4 id="1-1-15-TiDB-是否支持-select-for-update？"><a href="#1-1-15-TiDB-是否支持-select-for-update？" class="headerlink" title="1.1.15 TiDB 是否支持 select for update？"></a>1.1.15 TiDB 是否支持 select for update？</h4><p>支持，但语义上和 MySQL 有区别，TiDB 是分布式数据库，采用的乐观锁机制，也就说 select for update 不在事务开启就锁住数据，而是其他事务在提交的时候进行冲突检查，如有冲突，会进行回滚。</p><h4 id="1-1-16-TiDB-的-codec-能保证-UTF8-的字符串是-memcomparable-的吗？我们的-key-需要支持-UTF8，有什么编码建议吗？"><a href="#1-1-16-TiDB-的-codec-能保证-UTF8-的字符串是-memcomparable-的吗？我们的-key-需要支持-UTF8，有什么编码建议吗？" class="headerlink" title="1.1.16 TiDB 的 codec 能保证 UTF8 的字符串是 memcomparable 的吗？我们的 key 需要支持 UTF8，有什么编码建议吗？"></a>1.1.16 TiDB 的 codec 能保证 UTF8 的字符串是 memcomparable 的吗？我们的 key 需要支持 UTF8，有什么编码建议吗？</h4><p>TiDB 字符集默认就是 UTF8 而且目前只支持 UTF8，字符串就是 memcomparable 格式的。</p><h4 id="1-1-17-TiDB-用户名长度限制？"><a href="#1-1-17-TiDB-用户名长度限制？" class="headerlink" title="1.1.17 TiDB 用户名长度限制？"></a>1.1.17 TiDB 用户名长度限制？</h4><p>在 TiDB 中用户名最长为 32 字符。</p><h4 id="1-1-18-TiDB-是否支持-XA？"><a href="#1-1-18-TiDB-是否支持-XA？" class="headerlink" title="1.1.18 TiDB 是否支持 XA？"></a>1.1.18 TiDB 是否支持 XA？</h4><p>虽然 TiDB 的 JDBC 驱动用的就是 MySQL JDBC（Connector / J），但是当使用 Atomikos 的时候，数据源要配置成类似这样的配置：<code>type=&quot;com.mysql.jdbc.jdbc2.optional.MysqlXADataSource&quot;</code>。MySQL JDBC XADataSource 连接 TiDB 的模式目前是不支持的。MySQL JDBC 中配置好的 XADataSource 模式，只对 MySQL 数据库起作用（DML 去修改 redo 等）。</p><p>Atomikos 配好两个数据源后，JDBC 驱动都要设置成 XA 模式，然后 Atomikos 在操作 TM 和 RM（DB）的时候，会通过数据源的配置，发起带有 XA 指令到 JDBC 层，JDBC 层 XA 模式启用的情况下，会对 InnoDB（如果是 MySQL 的话）下发操作一连串 XA 逻辑的动作，包括 DML 去变更 redo log 等，就是两阶段递交的那些操作。TiDB 目前的引擎版本中，没有对上层应用层 JTA / XA 的支持，不解析这些 Atomikos 发过来的 XA 类型的操作。</p><p>MySQL 是单机数据库，只能通过 XA 来满足跨数据库事务，而 TiDB 本身就通过 Google 的 Percolator 事务模型支持分布式事务，性能稳定性比 XA 要高出很多，所以不会也不需要支持 XA。</p><h4 id="1-1-19-show-processlist-是否显示系统进程号？"><a href="#1-1-19-show-processlist-是否显示系统进程号？" class="headerlink" title="1.1.19 show processlist 是否显示系统进程号？"></a>1.1.19 show processlist 是否显示系统进程号？</h4><p>TiDB 的 <code>show processlist</code> 与 MySQL 的 <code>show processlist</code> 显示内容基本一样，不会显示系统进程号，而 ID 表示当前的 session ID。其中 TiDB 的 <code>show processlist</code> 和 MySQL 的 <code>show processlist</code> 区别如下：</p><p>1）由于 TiDB 是分布式数据库，tidb-server 实例是无状态的 SQL 解析和执行引擎（详情可参考 <a href="/overview.md#tidb-整体架构">TiDB 整体架构</a>），用户使用 MySQL 客户端登录的是哪个 tidb-server，<code>show processlist</code> 就会显示当前连接的这个 tidb-server 中执行的 session 列表，不是整个集群中运行的全部 session 列表；而 MySQL 是单机数据库，<code>show processlist</code> 列出的是当前整个 MySQL 数据库的全部执行 SQL 列表。</p><p>2）TiDB 的 <code>show processlist</code> 显示内容比起 MySQL 来讲，多了一个当前 session 使用内存的估算值（单位 Byte）。</p><h4 id="1-1-20-如何修改用户名密码和权限？"><a href="#1-1-20-如何修改用户名密码和权限？" class="headerlink" title="1.1.20 如何修改用户名密码和权限？"></a>1.1.20 如何修改用户名密码和权限？</h4><p>TiDB 作为分布式数据库，在 TiDB 中修改用户密码建议使用 <code>set password for &#39;root&#39;@&#39;%&#39; = &#39;0101001&#39;;</code> 或 <code>alter</code> 方法，不推荐使用 <code>update mysql.user</code> 的方法进行，这种方法可能会造成其它节点刷新不及时的情况。修改权限也一样，都建议采用官方的标准语法。详情可参考 <a href="/reference/security/user-account-management.md">TiDB 用户账户管理</a>。</p><h4 id="1-1-21-TiDB-中，为什么出现后插入数据的自增-ID-反而小？"><a href="#1-1-21-TiDB-中，为什么出现后插入数据的自增-ID-反而小？" class="headerlink" title="1.1.21 TiDB 中，为什么出现后插入数据的自增 ID 反而小？"></a>1.1.21 TiDB 中，为什么出现后插入数据的自增 ID 反而小？</h4><p>TiDB 的自增 ID (<code>AUTO_INCREMENT</code>) 只保证自增且唯一，并不保证连续分配。TiDB 目前采用批量分配的方式，所以如果在多台 TiDB 上同时插入数据，分配的自增 ID 会不连续。当多个线程并发往不同的 tidb-server 插入数据的时候，有可能会出现后插入的数据自增 ID 小的情况。此外，TiDB允许给整型类型的字段指定 AUTO_INCREMENT，且一个表只允许一个属性为 <code>AUTO_INCREMENT</code> 的字段。详情可参考<a href="/reference/mysql-compatibility.md#自增-id">CREATE TABLE 语法</a>。</p><h4 id="1-1-22-sql-mode-默认除了通过命令-set-修改，配置文件怎么修改？"><a href="#1-1-22-sql-mode-默认除了通过命令-set-修改，配置文件怎么修改？" class="headerlink" title="1.1.22 sql_mode 默认除了通过命令 set 修改，配置文件怎么修改？"></a>1.1.22 sql_mode 默认除了通过命令 set 修改，配置文件怎么修改？</h4><p>TiDB 的 sql_mode 与 MySQL 的 sql_mode 设置方法有一些差别，TiDB 不支持配置文件配置设置数据库的 sql_mode，而只能使用 set 命令去设置，具体方法为：<code>set @@global.sql_mode = &#39;STRICT_TRANS_TABLES&#39;;</code>。</p><h4 id="1-1-23-TiDB-支持哪些认证协议，过程是怎样的？"><a href="#1-1-23-TiDB-支持哪些认证协议，过程是怎样的？" class="headerlink" title="1.1.23 TiDB 支持哪些认证协议，过程是怎样的？"></a>1.1.23 TiDB 支持哪些认证协议，过程是怎样的？</h4><p>这一层跟 MySQL 一样，走的 SASL 认证协议，用于用户登录认证，对密码的处理流程。</p><p>客户端连接 TiDB 的时候，走的是 challenge-response（挑战-应答）的认证模式，过程如下：</p><p>第一步：客户端连接服务器；</p><p>第二步：服务器发送随机字符串 challenge 给客户端；</p><p>第三步：客户端发送 username + response 给服务器；</p><p>第四步：服务器验证 response。</p><h3 id="1-2-TiDB-原理"><a href="#1-2-TiDB-原理" class="headerlink" title="1.2 TiDB 原理"></a>1.2 TiDB 原理</h3><h4 id="1-2-1-存储-TiKV"><a href="#1-2-1-存储-TiKV" class="headerlink" title="1.2.1 存储 TiKV"></a>1.2.1 存储 TiKV</h4><h5 id="1-2-1-1-TiKV-详细解读"><a href="#1-2-1-1-TiKV-详细解读" class="headerlink" title="1.2.1.1 TiKV 详细解读"></a>1.2.1.1 TiKV 详细解读</h5><p><a href="http://t.cn/RTKRRWv" target="_blank" rel="noopener">三篇文章了解 TiDB 技术内幕 - 说存储</a></p><h4 id="1-2-2-计算-TiDB"><a href="#1-2-2-计算-TiDB" class="headerlink" title="1.2.2 计算 TiDB"></a>1.2.2 计算 TiDB</h4><h5 id="1-2-2-1-TiDB-详细解读"><a href="#1-2-2-1-TiDB-详细解读" class="headerlink" title="1.2.2.1 TiDB 详细解读"></a>1.2.2.1 TiDB 详细解读</h5><p><a href="http://t.cn/RTKRkBh" target="_blank" rel="noopener">三篇文章了解 TiDB 技术内幕 - 说计算</a></p><h4 id="1-2-3-调度-PD"><a href="#1-2-3-调度-PD" class="headerlink" title="1.2.3 调度 PD"></a>1.2.3 调度 PD</h4><h5 id="1-2-3-1-PD-详细解读"><a href="#1-2-3-1-PD-详细解读" class="headerlink" title="1.2.3.1 PD 详细解读"></a>1.2.3.1 PD 详细解读</h5><p><a href="http://t.cn/RTKEZ0U" target="_blank" rel="noopener">三篇文章了解 TiDB 技术内幕 - 谈调度</a></p><h2 id="二、安装部署升级"><a href="#二、安装部署升级" class="headerlink" title="二、安装部署升级"></a>二、安装部署升级</h2><h3 id="2-1-环境准备"><a href="#2-1-环境准备" class="headerlink" title="2.1 环境准备"></a>2.1 环境准备</h3><h4 id="2-1-1-操作系统版本要求"><a href="#2-1-1-操作系统版本要求" class="headerlink" title="2.1.1 操作系统版本要求"></a>2.1.1 操作系统版本要求</h4><table><thead><tr><th><strong>Linux 操作系统平台</strong></th><th><strong>版本</strong></th></tr></thead><tbody><tr><td>Red Hat Enterprise Linux</td><td>7.3 及以上</td></tr><tr><td>CentOS</td><td>7.3 及以上</td></tr><tr><td>Oracle Enterprise Linux</td><td>7.3 及以上</td></tr></tbody></table><h5 id="2-1-1-1-为什么要在-CentOS-7-上部署-TiDB-集群？"><a href="#2-1-1-1-为什么要在-CentOS-7-上部署-TiDB-集群？" class="headerlink" title="2.1.1.1  为什么要在 CentOS 7 上部署 TiDB 集群？"></a>2.1.1.1  为什么要在 CentOS 7 上部署 TiDB 集群？</h5><p>TiDB 作为一款开源分布式 NewSQL 数据库，可以很好的部署和运行在 Intel 架构服务器环境及主流虚拟化环境，并支持绝大多数的主流硬件网络，作为一款高性能数据库系统，TiDB 支持主流的 Linux 操作系统环境，具体可以参考 TiDB 的<a href="/how-to/deploy/hardware-recommendations.md">官方部署要求</a>。其中 TiDB 在 CentOS 7.3 的环境下进行大量的测试，同时也有很多这个操作系统的部署最佳实践，因此，我们推荐客户在部署 TiDB 的时候使用 CentOS 7.3+ 以上的Linux 操作系统。</p><h4 id="2-1-2-硬件要求"><a href="#2-1-2-硬件要求" class="headerlink" title="2.1.2 硬件要求"></a>2.1.2 硬件要求</h4><p>TiDB 支持部署和运行在 Intel x86-64 架构的 64 位通用硬件服务器平台。对于开发，测试，及生产环境的服务器硬件配置有以下要求和建议：</p><h5 id="2-1-2-1-开发及测试环境"><a href="#2-1-2-1-开发及测试环境" class="headerlink" title="2.1.2.1 开发及测试环境"></a>2.1.2.1 开发及测试环境</h5><table><thead><tr><th><strong>组件</strong></th><th><strong>CPU</strong></th><th><strong>内存</strong></th><th><strong>本地存储</strong></th><th><strong>网络</strong></th><th><strong>实例数量(最低要求)</strong></th></tr></thead><tbody><tr><td>TiDB</td><td>8核+</td><td>16 GB+</td><td>SAS, 200 GB+</td><td>千兆网卡</td><td>1（可与 PD 同机器）</td></tr><tr><td>PD</td><td>8核+</td><td>16 GB+</td><td>SAS, 200 GB+</td><td>千兆网卡</td><td>1（可与 TiDB 同机器）</td></tr><tr><td>TiKV</td><td>8核+</td><td>32 GB+</td><td>SSD, 200 GB+</td><td>千兆网卡</td><td>3</td></tr><tr><td></td><td></td><td></td><td></td><td>服务器总计</td><td>4</td></tr></tbody></table><h5 id="2-1-2-2-线上环境"><a href="#2-1-2-2-线上环境" class="headerlink" title="2.1.2.2 线上环境"></a>2.1.2.2 线上环境</h5><table><thead><tr><th><strong>组件</strong></th><th><strong>CPU</strong></th><th><strong>内存</strong></th><th><strong>硬盘类型</strong></th><th><strong>网络</strong></th><th><strong>实例数量(最低要求)</strong></th></tr></thead><tbody><tr><td>TiDB</td><td>16核+</td><td>48 GB+</td><td>SAS</td><td>万兆网卡（2块最佳）</td><td>2</td></tr><tr><td>PD</td><td>8核+</td><td>16 GB+</td><td>SSD</td><td>万兆网卡（2块最佳）</td><td>3</td></tr><tr><td>TiKV</td><td>16核+</td><td>48 GB+</td><td>SSD</td><td>万兆网卡（2块最佳）</td><td>3</td></tr><tr><td>监控</td><td>8核+</td><td>16 GB+</td><td>SAS</td><td>千兆网卡</td><td>1</td></tr><tr><td></td><td></td><td></td><td></td><td>服务器总计</td><td>9</td></tr></tbody></table><h5 id="2-1-2-3-2-块网卡的目的是？万兆的目的是？"><a href="#2-1-2-3-2-块网卡的目的是？万兆的目的是？" class="headerlink" title="2.1.2.3 2 块网卡的目的是？万兆的目的是？"></a>2.1.2.3 2 块网卡的目的是？万兆的目的是？</h5><p>作为一个分布式集群，TiDB 对时间的要求还是比较高的，尤其是 PD 需要分发唯一的时间戳，如果 PD 时间不统一，如果有 PD 切换，将会等待更长的时间。2 块网卡可以做 bond，保证数据传输的稳定，万兆可以保证数据传输的速度，千兆网卡容易出现瓶颈，我们强烈建议使用万兆网卡。</p><h5 id="2-1-2-4-SSD-不做-RAID-是否可行？"><a href="#2-1-2-4-SSD-不做-RAID-是否可行？" class="headerlink" title="2.1.2.4 SSD 不做 RAID 是否可行？"></a>2.1.2.4 SSD 不做 RAID 是否可行？</h5><p>资源可接受的话，我们建议做 RAID 10，如果资源有限，也可以不做 RAID。</p><h5 id="2-1-2-5-TiDB-集群各个组件的配置推荐？"><a href="#2-1-2-5-TiDB-集群各个组件的配置推荐？" class="headerlink" title="2.1.2.5 TiDB 集群各个组件的配置推荐？"></a>2.1.2.5 TiDB 集群各个组件的配置推荐？</h5><ul><li>TiDB 需要 CPU 和内存比较好的机器，参考官网配置要求，如果后期需要开启 Binlog，根据业务量的评估和 GC 时间的要求，也需要本地磁盘大一点，不要求 SSD 磁盘；</li><li>PD 里面存了集群元信息，会有频繁的读写请求，对磁盘 I/O 要求相对比较高，磁盘太差会影响整个集群性能，推荐 SSD 磁盘，空间不用太大。另外集群 Region 数量越多对 CPU、内存的要求越高；</li><li>TiKV 对 CPU、内存、磁盘要求都比较高，一定要用 SSD 磁盘。</li></ul><p>详情可参考 <a href="/how-to/deploy/hardware-recommendations.md">TiDB 软硬件环境需求</a>。</p><h3 id="2-2-安装部署"><a href="#2-2-安装部署" class="headerlink" title="2.2 安装部署"></a>2.2 安装部署</h3><h4 id="2-2-1-Ansible-部署方式（强烈推荐）"><a href="#2-2-1-Ansible-部署方式（强烈推荐）" class="headerlink" title="2.2.1 Ansible 部署方式（强烈推荐）"></a>2.2.1 Ansible 部署方式（强烈推荐）</h4><p>详细可参考<a href="/how-to/deploy/orchestrated/ansible.md">使用 TiDB Ansible 部署 TiDB 集群</a>。</p><h5 id="2-2-1-1-为什么修改了-TiKV-PD-的-toml-配置文件，却没有生效？"><a href="#2-2-1-1-为什么修改了-TiKV-PD-的-toml-配置文件，却没有生效？" class="headerlink" title="2.2.1.1 为什么修改了 TiKV/PD 的 toml 配置文件，却没有生效？"></a>2.2.1.1 为什么修改了 TiKV/PD 的 toml 配置文件，却没有生效？</h5><p>这种情况一般是因为没有使用 <code>--config</code> 参数来指定配置文件（目前只会出现在 binary 部署的场景），TiKV/PD 会按默认值来设置。如果要使用配置文件，请设置 TiKV/PD 的 <code>--config</code> 参数。对于 TiKV 组件，修改配置后重启服务即可；对于 PD 组件，只会在第一次启动时读取配置文件，之后可以使用 pd-ctl 的方式来修改配置，详情可参考 <a href="/reference/configuration/pd-server/configuration.md">PD 配置参数</a>。</p><h5 id="2-2-1-2-TiDB-监控框架-Prometheus-Grafana-监控机器建议单独还是多台部署？"><a href="#2-2-1-2-TiDB-监控框架-Prometheus-Grafana-监控机器建议单独还是多台部署？" class="headerlink" title="2.2.1.2 TiDB 监控框架 Prometheus + Grafana 监控机器建议单独还是多台部署？"></a>2.2.1.2 TiDB 监控框架 Prometheus + Grafana 监控机器建议单独还是多台部署？</h5><p>监控机建议单独部署。建议 CPU 8 core，内存 16 GB 以上，硬盘 500 GB 以上。</p><h5 id="2-2-1-3-有一部分监控信息显示不出来？"><a href="#2-2-1-3-有一部分监控信息显示不出来？" class="headerlink" title="2.2.1.3 有一部分监控信息显示不出来？"></a>2.2.1.3 有一部分监控信息显示不出来？</h5><p>查看访问监控的机器时间跟集群内机器的时间差，如果比较大，更正时间后即可显示正常。</p><h5 id="2-2-1-4-supervise-svc-svstat-服务具体起什么作用？"><a href="#2-2-1-4-supervise-svc-svstat-服务具体起什么作用？" class="headerlink" title="2.2.1.4 supervise/svc/svstat 服务具体起什么作用？"></a>2.2.1.4 supervise/svc/svstat 服务具体起什么作用？</h5><ul><li>supervise 守护进程</li><li>svc 启停服务</li><li>svstat 查看进程状态</li></ul><h5 id="2-2-1-5-inventory-ini-变量参数解读"><a href="#2-2-1-5-inventory-ini-变量参数解读" class="headerlink" title="2.2.1.5 inventory.ini 变量参数解读"></a>2.2.1.5 inventory.ini 变量参数解读</h5><table><thead><tr><th><strong>变量</strong></th><th><strong>含义</strong></th></tr></thead><tbody><tr><td>cluster_name</td><td>集群名称，可调整</td></tr><tr><td>tidb_version</td><td>TiDB 版本，TiDB Ansible 各分支默认已配置</td></tr><tr><td>deployment_method</td><td>部署方式，默认为 binary，可选 docker</td></tr><tr><td>process_supervision</td><td>进程监管方式，默认为 systemd，可选 supervise</td></tr><tr><td>timezone</td><td>修改部署目标机器时区，默认为 Asia/Shanghai, 可调整，与set_timezone 变量结合使用</td></tr><tr><td>set_timezone</td><td>默认为 True，即修改部署目标机器时区，关闭可修改为 False</td></tr><tr><td>enable_elk</td><td>目前不支持，请忽略</td></tr><tr><td>enable_firewalld</td><td>开启防火墙，默认不开启</td></tr><tr><td>enable_ntpd</td><td>检测部署目标机器 NTP 服务，默认为 True，请勿关闭</td></tr><tr><td>machine_benchmark</td><td>检测部署目标机器磁盘 IOPS，默认为 True，请勿关闭</td></tr><tr><td>set_hostname</td><td>根据 IP 修改部署目标机器主机名，默认为 False</td></tr><tr><td>enable_binlog</td><td>是否部署 pump 并开启 binlog，默认为 False，依赖 Kafka 集群，参见 zookeeper_addrs 变量</td></tr><tr><td>zookeeper_addrs</td><td>binlog Kafka 集群的 zookeeper 地址</td></tr><tr><td>enable_slow_query_log</td><td>TiDB 慢查询日志记录到单独文件(/log/tidb_slow_query.log)，默认为 False，记录到 tidb 日志</td></tr><tr><td>deploy_without_tidb</td><td>KV 模式，不部署 TiDB 服务，仅部署 PD、TiKV 及监控服务，请将 inventory.ini 文件中 tidb_servers 主机组 IP 设置为空。</td></tr></tbody></table><h4 id="2-2-2-TiDB-离线-Ansible-部署方案"><a href="#2-2-2-TiDB-离线-Ansible-部署方案" class="headerlink" title="2.2.2 TiDB 离线 Ansible 部署方案"></a>2.2.2 TiDB 离线 Ansible 部署方案</h4><p>首先这不是我们建议的方式，如果中控机没有外网，也可以通过离线 Ansible 部署方式，详情可参考<a href="/how-to/deploy/orchestrated/offline-ansible.md">离线 TiDB Ansible 部署方案</a>。</p><h4 id="2-2-3-Docker-Compose-快速构建集群（单机部署）"><a href="#2-2-3-Docker-Compose-快速构建集群（单机部署）" class="headerlink" title="2.2.3 Docker Compose 快速构建集群（单机部署）"></a>2.2.3 Docker Compose 快速构建集群（单机部署）</h4><p>使用 docker-compose 在本地一键拉起一个集群，包括集群监控，还可以根据需求自定义各个组件的软件版本和实例个数，以及自定义配置文件，这种只限于开发环境，详细可参考<a href="/how-to/get-started/deploy-tidb-from-docker-compose.md">官方文档</a>。</p><h4 id="2-2-4-如何单独记录-TiDB-中的慢查询日志，如何定位慢查询-SQL？"><a href="#2-2-4-如何单独记录-TiDB-中的慢查询日志，如何定位慢查询-SQL？" class="headerlink" title="2.2.4 如何单独记录 TiDB 中的慢查询日志，如何定位慢查询 SQL？"></a>2.2.4 如何单独记录 TiDB 中的慢查询日志，如何定位慢查询 SQL？</h4><p>1）TiDB 中，对慢查询的定义在 tidb-ansible 的 <code>conf/tidb.yml</code> 配置文件中，<code>slow-threshold: 300</code>，这个参数是配置慢查询记录阈值的，单位是 ms。</p><p>慢查询日志默认记录到 tidb.log 中，如果希望生成单独的慢查询日志文件，修改 inventory.ini 配置文件的参数 <code>enable_slow_query_log</code> 为 True。</p><p>如上配置修改之后，需要执行 <code>ansible-playbook rolling_update.yml --tags=tidb</code>，对 tidb-server 实例进行滚动升级，升级完成后，tidb-server 将在 <code>tidb_slow_query.log</code><br>文件中记录慢查询日志。</p><p>2）如果出现了慢查询，可以从 Grafana 监控定位到出现慢查询的 tidb-server 以及时间点，然后在对应节点查找日志中记录的 SQL 信息。</p><p>3）除了日志，还可以通过 <code>admin show slow</code> 命令查看，详情可参考 <a href="/how-to/maintain/identify-abnormal-queries/identify-slow-queries.md#admin-show-slow-命令"><code>admin show slow</code> 命令</a>。</p><h4 id="2-2-5-首次部署-TiDB-集群时，没有配置-tikv-的-Label-信息，在后续如何添加配置-Label？"><a href="#2-2-5-首次部署-TiDB-集群时，没有配置-tikv-的-Label-信息，在后续如何添加配置-Label？" class="headerlink" title="2.2.5 首次部署 TiDB 集群时，没有配置 tikv 的 Label 信息，在后续如何添加配置 Label？"></a>2.2.5 首次部署 TiDB 集群时，没有配置 tikv 的 Label 信息，在后续如何添加配置 Label？</h4><p>TiDB 的 Label 设置是与集群的部署架构相关的，是集群部署中的重要内容，是 PD 进行全局管理和调度的依据。如果集群在初期部署过程中没有设置 Label，需要在后期对部署结构进行调整，就需要手动通过 PD 的管理工具 pd-ctl 来添加 location-labels 信息，例如：<code>config set location-labels &quot;zone,rack,host&quot;</code>（根据实际的 label 层级名字配置）。</p><p>pd-ctl 的使用参考 <a href="/reference/tools/pd-control.md">PD Control 使用说明</a>。</p><h4 id="2-2-6-为什么测试磁盘的-dd-命令用-oflag-direct-这个选项？"><a href="#2-2-6-为什么测试磁盘的-dd-命令用-oflag-direct-这个选项？" class="headerlink" title="2.2.6 为什么测试磁盘的 dd 命令用 oflag=direct 这个选项？"></a>2.2.6 为什么测试磁盘的 dd 命令用 oflag=direct 这个选项？</h4><p>Direct 模式就是把写入请求直接封装成 I/O 指令发到磁盘，这样是为了绕开文件系统的缓存，可以直接测试磁盘的真实的 I/O 读写能力。</p><h4 id="2-2-7-如何用-fio-命令测试-TiKV-实例的磁盘性能？"><a href="#2-2-7-如何用-fio-命令测试-TiKV-实例的磁盘性能？" class="headerlink" title="2.2.7 如何用 fio 命令测试 TiKV 实例的磁盘性能？"></a>2.2.7 如何用 fio 命令测试 TiKV 实例的磁盘性能？</h4><ul><li><p>随机读测试：</p><p>   copyable “shell-regular” </p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./fio -ioengine=psync -bs=32k -fdatasync=1 -thread -rw=randread -size=10G -filename=fio_randread_test.txt -name=<span class="string">'fio randread test'</span> -iodepth=4 -runtime=60 -numjobs=4 -group_reporting --output-format=json --output=fio_randread_result.json</span><br></pre></td></tr></table></figure></li><li><p>顺序写和随机读混合测试：</p><p>   copyable “shell-regular” </p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./fio -ioengine=psync -bs=32k -fdatasync=1 -thread -rw=randrw -percentage_random=100,0 -size=10G -filename=fio_randread_write_test.txt -name=<span class="string">'fio mixed randread and sequential write test'</span> -iodepth=4 -runtime=60 -numjobs=4 -group_reporting --output-format=json --output=fio_randread_write_test.json</span><br></pre></td></tr></table></figure></li></ul><h4 id="2-2-8-使用-TiDB-Ansible-部署-TiDB-集群的时候，遇到-UNREACHABLE-quot-msg-quot-quot-Failed-to-connect-to-the-host-via-ssh-quot-报错是什么原因？"><a href="#2-2-8-使用-TiDB-Ansible-部署-TiDB-集群的时候，遇到-UNREACHABLE-quot-msg-quot-quot-Failed-to-connect-to-the-host-via-ssh-quot-报错是什么原因？" class="headerlink" title="2.2.8 使用 TiDB Ansible 部署 TiDB 集群的时候，遇到 UNREACHABLE! &quot;msg&quot;: &quot;Failed to connect to the host via ssh: &quot; 报错是什么原因？"></a>2.2.8 使用 TiDB Ansible 部署 TiDB 集群的时候，遇到 <code>UNREACHABLE! &quot;msg&quot;: &quot;Failed to connect to the host via ssh: &quot;</code> 报错是什么原因？</h4><p>有两种可能性：</p><ul><li><p>ssh 互信的准备工作未做好，建议严格参照我们的<a href="/how-to/deploy/orchestrated/ansible.md">官方文档步骤</a>配置互信，并使用命令 <code>ansible -i inventory.ini all -m shell -a &#39;whoami&#39; -b</code> 来验证互信配置是否成功。</p></li><li><p>如果涉及到单服务器分配了多角色的场景，例如多组件混合部署或单台服务器部署了多个 TiKV 实例，可能是由于 ssh 复用的机制引起这个报错，可以使用 <code>ansible … -f 1</code> 的选项来规避这个报错。</p></li></ul><h3 id="2-3-升级"><a href="#2-3-升级" class="headerlink" title="2.3 升级"></a>2.3 升级</h3><h4 id="2-3-1-如何使用-Ansible-滚动升级？"><a href="#2-3-1-如何使用-Ansible-滚动升级？" class="headerlink" title="2.3.1 如何使用 Ansible 滚动升级？"></a>2.3.1 如何使用 Ansible 滚动升级？</h4><p>滚动升级 TiKV 节点( 只升级单独服务 )</p><p><code>ansible-playbook rolling_update.yml --tags=tikv</code></p><p>滚动升级所有服务</p><p><code>ansible-playbook rolling_update.yml</code></p><h4 id="2-3-2-滚动升级有那些影响"><a href="#2-3-2-滚动升级有那些影响" class="headerlink" title="2.3.2 滚动升级有那些影响?"></a>2.3.2 滚动升级有那些影响?</h4><p>滚动升级 TiDB 服务，滚动升级期间不影响业务运行，需要配置最小集群拓扑（TiDB * 2、PD * 3、TiKV * 3），如果集群环境中有 Pump/Drainer 服务，建议先停止 Drainer 后滚动升级（升级 TiDB 时会升级 Pump）。</p><h4 id="2-3-3-Binary-如何升级？"><a href="#2-3-3-Binary-如何升级？" class="headerlink" title="2.3.3 Binary 如何升级？"></a>2.3.3 Binary 如何升级？</h4><p>Binary 不是我们建议的安装方式，对升级支持也不友好，建议换成 Ansible 部署。</p><h4 id="2-3-4-一般升级选择升级-TiKV-还是所有组件都升级？"><a href="#2-3-4-一般升级选择升级-TiKV-还是所有组件都升级？" class="headerlink" title="2.3.4 一般升级选择升级 TiKV 还是所有组件都升级？"></a>2.3.4 一般升级选择升级 TiKV 还是所有组件都升级？</h4><p>常规需要一起升，因为整个版本都是一起测试的，单独升级只限当发生一个紧急故障时，需要单独对一个有问题的角色做升级。</p><h4 id="2-3-5-启动集群或者升级集群过程中出现-“Timeout-when-waiting-for-search-string-200-OK”-是什么原因？如何处理？"><a href="#2-3-5-启动集群或者升级集群过程中出现-“Timeout-when-waiting-for-search-string-200-OK”-是什么原因？如何处理？" class="headerlink" title="2.3.5 启动集群或者升级集群过程中出现 “Timeout when waiting for search string 200 OK” 是什么原因？如何处理？"></a>2.3.5 启动集群或者升级集群过程中出现 “Timeout when waiting for search string 200 OK” 是什么原因？如何处理？</h4><p>可能有以下几种原因：进程没有正常启动；端口被占用；进程没有正常停掉；停掉集群的情况下使用 rolling_update.yml 来升级集群（操作错误）。</p><p>处理方式：登录到相应节点查看进程或者端口的状态；纠正错误的操作步骤。</p><h2 id="三、集群管理"><a href="#三、集群管理" class="headerlink" title="三、集群管理"></a>三、集群管理</h2><h3 id="3-1-集群日常管理"><a href="#3-1-集群日常管理" class="headerlink" title="3.1 集群日常管理"></a>3.1 集群日常管理</h3><h4 id="3-1-1-Ansible-常见运维操作有那些？"><a href="#3-1-1-Ansible-常见运维操作有那些？" class="headerlink" title="3.1.1 Ansible 常见运维操作有那些？"></a>3.1.1 Ansible 常见运维操作有那些？</h4><table><thead><tr><th><strong>任务</strong></th><th><strong>Playbook</strong></th></tr></thead><tbody><tr><td>启动集群</td><td>ansible-playbook start.yml</td></tr><tr><td>停止集群</td><td>ansible-playbook stop.yml</td></tr><tr><td>销毁集群</td><td>ansible-playbook unsafe_cleanup.yml (若部署目录为挂载点，会报错，可忽略）</td></tr><tr><td>清除数据(测试用)</td><td>ansible-playbook cleanup_data.yml</td></tr><tr><td>滚动升级</td><td>ansible-playbook rolling_update.yml</td></tr><tr><td>滚动升级 TiKV</td><td>ansible-playbook rolling_update.yml –tags=tikv</td></tr><tr><td>滚动升级除 PD 外模块</td><td>ansible-playbook rolling_update.yml –skip-tags=pd</td></tr><tr><td>滚动升级监控组件</td><td>ansible-playbook rolling_update_monitor.yml</td></tr></tbody></table><h4 id="3-1-2-TiDB-如何登录？"><a href="#3-1-2-TiDB-如何登录？" class="headerlink" title="3.1.2 TiDB 如何登录？"></a>3.1.2 TiDB 如何登录？</h4><p>和 MySQL 登录方式一样，可以按照下面例子进行登录。</p><p><code>mysql -h 127.0.0.1 -uroot -P4000</code></p><h4 id="3-1-3-TiDB-如何修改数据库系统变量？"><a href="#3-1-3-TiDB-如何修改数据库系统变量？" class="headerlink" title="3.1.3 TiDB 如何修改数据库系统变量？"></a>3.1.3 TiDB 如何修改数据库系统变量？</h4><p>和 MySQL 一样，TiDB 也分为静态参数和固态参数，静态参数可以直接通过<code>set global xxx = n</code>的方式进行修改，不过新参数值只限于该实例生命周期有效。</p><h4 id="3-1-4-TiDB-TiKV-有哪些数据目录？"><a href="#3-1-4-TiDB-TiKV-有哪些数据目录？" class="headerlink" title="3.1.4 TiDB (TiKV) 有哪些数据目录？"></a>3.1.4 TiDB (TiKV) 有哪些数据目录？</h4><p>默认在 <a href="/reference/configuration/tikv-server/configuration.md#--data-dir"><code>--data-dir</code></a> 目录下，其中包括 backup、db、raft、snap 四个目录，分别存储备份、数据、raft 数据及镜像数据。</p><h4 id="3-1-5-TiDB-有哪些系统表？"><a href="#3-1-5-TiDB-有哪些系统表？" class="headerlink" title="3.1.5 TiDB 有哪些系统表？"></a>3.1.5 TiDB 有哪些系统表？</h4><p>和 MySQL 类似，TiDB 中也有系统表，用于存放数据库运行时所需信息，具体信息参考 <a href="/reference/system-databases/mysql.md">TiDB 系统数据库</a>文档。</p><h4 id="3-1-6-TiDB-各节点服务器下是否有日志文件，如何管理？"><a href="#3-1-6-TiDB-各节点服务器下是否有日志文件，如何管理？" class="headerlink" title="3.1.6 TiDB 各节点服务器下是否有日志文件，如何管理？"></a>3.1.6 TiDB 各节点服务器下是否有日志文件，如何管理？</h4><p>默认情况下各节点服务器会在日志中输出标准错误，如果启动的时候通过 <code>--log-file</code> 参数指定了日志文件，那么日志会输出到指定的文件中，并且按天做 rotation。</p><h4 id="3-1-7-如何规范停止-TiDB？"><a href="#3-1-7-如何规范停止-TiDB？" class="headerlink" title="3.1.7 如何规范停止 TiDB？"></a>3.1.7 如何规范停止 TiDB？</h4><p>如果是用 Ansible 部署的，可以使用 <code>ansible-playbook stop.yml</code> 命令停止 TiDB 集群。如果不是 Ansible 部署的，可以直接 kill 掉所有服务。如果使用 kill 命令，TiDB 的组件会做 graceful 的 shutdown。</p><h4 id="3-1-8-TiDB-里面可以执行-kill-命令吗？"><a href="#3-1-8-TiDB-里面可以执行-kill-命令吗？" class="headerlink" title="3.1.8 TiDB 里面可以执行 kill 命令吗？"></a>3.1.8 TiDB 里面可以执行 kill 命令吗？</h4><ul><li>可以 kill DML 语句，首先使用 <code>show processlist</code>，找到对应 session 的 id，然后执行 <code>kill tidb [session id]</code>。</li><li>可以 kill DDL 语句，首先使用 <code>admin show ddl jobs</code>，查找需要 kill 的 DDL job ID，然后执行 <code>admin cancel ddl jobs &#39;job_id&#39; [, &#39;job_id&#39;] ...</code>。具体可以参考 <a href="/reference/sql/statements/admin.md">admin 操作</a>。</li></ul><h4 id="3-1-9-TiDB-是否支持会话超时？"><a href="#3-1-9-TiDB-是否支持会话超时？" class="headerlink" title="3.1.9 TiDB 是否支持会话超时？"></a>3.1.9 TiDB 是否支持会话超时？</h4><p>TiDB 暂不支持数据库层面的会话超时，目前想要实现超时，在没 LB（Load Balancing）的时候，需要应用侧记录发起的 Session 的 ID，通过应用自定义超时，超时以后需要到发起 Query 的节点上用 <code>kill tidb [session id]</code> 来杀掉 SQL。目前建议使用应用程序来实现会话超时，当达到超时时间，应用层就会抛出异常继续执行后续的程序段。</p><h4 id="3-1-10-TiDB-生产环境的版本管理策略是怎么样的？如何尽可能避免频繁升级？"><a href="#3-1-10-TiDB-生产环境的版本管理策略是怎么样的？如何尽可能避免频繁升级？" class="headerlink" title="3.1.10 TiDB 生产环境的版本管理策略是怎么样的？如何尽可能避免频繁升级？"></a>3.1.10 TiDB 生产环境的版本管理策略是怎么样的？如何尽可能避免频繁升级？</h4><p>TiDB 版本目前逐步标准化，每次 Release 都包含详细的 Change log，版本功能<a href="https://github.com/pingcap/TiDB/releases" target="_blank" rel="noopener">变化详情</a>，生产环境是否有必要升级取决于业务系统，建议升级之前详细了解前后版本的功能差异。</p><p>版本号说明参考：Release Version: <code>v1.0.3-1-ga80e796</code></p><ul><li><code>v1.0.3</code> 表示 GA 标准版</li><li><code>1</code> 表示该版本 commit 1 次</li><li><code>ga80e796</code> 代表版本的 <code>git-hash</code></li></ul><h4 id="3-1-11-分不清-TiDB-master-版本之间的区别，经常用错-TiDB-Ansible-版本"><a href="#3-1-11-分不清-TiDB-master-版本之间的区别，经常用错-TiDB-Ansible-版本" class="headerlink" title="3.1.11 分不清 TiDB master 版本之间的区别，经常用错 TiDB Ansible 版本?"></a>3.1.11 分不清 TiDB master 版本之间的区别，经常用错 TiDB Ansible 版本?</h4><p>TiDB 目前社区非常活跃，在 1.0 GA 版本发布后，还在不断的优化和修改 BUG，因此 TiDB 的版本更新周期比较快，会不定期有新版本发布，请关注我们的<a href="https://pingcap.com/weekly/" target="_blank" rel="noopener">新版本发布官方网站</a>。此外 TiDB 安装推荐使用 TiDB Ansible 进行安装，TiDB Ansible 的版本也会随着 TiDB 的版本发布进行更新，因此建议用户在安装升级新版本的时候使用最新的 TiDB Ansible 安装包版本进行安装。此外，在 TiDB 1.0 GA 版本后，对 TiDB 的版本号进行了统一管理，TiDB 的版本可以通过以下两种方式进行查看：</p><ul><li>通过 <code>select tidb_version()</code> 进行查看</li><li>通过执行 <code>tidb-server -V</code> 进行查看</li></ul><h4 id="3-1-12-有没有图形化部署-TiDB-的工具？"><a href="#3-1-12-有没有图形化部署-TiDB-的工具？" class="headerlink" title="3.1.12 有没有图形化部署 TiDB 的工具？"></a>3.1.12 有没有图形化部署 TiDB 的工具？</h4><p>暂时没有。</p><h4 id="3-1-13-TiDB-如何进行水平扩展？"><a href="#3-1-13-TiDB-如何进行水平扩展？" class="headerlink" title="3.1.13 TiDB 如何进行水平扩展？"></a>3.1.13 TiDB 如何进行水平扩展？</h4><p>当您的业务不断增长时，数据库可能会面临三方面瓶颈，第一是存储空间，第二是计算资源，第三是读写容量，这时可以对 TiDB 集群做水平扩展。</p><ul><li>如果是存储资源不够，可以通过添加 TiKV Server 节点来解决，新节点启动后，PD 会自动将其他节点的部分数据迁移过去，无需人工介入。</li><li>如果是计算资源不够，可以查看 TiDB Server 和 TiKV Server 节点的 CPU 消耗情况，再考虑添加 TiDB Server 节点或者是 TiKV Server 节点来解决，如添加 TiDB Server 节点，将其添加到前端 Load Balancer 配置之中即可。</li><li>如果是容量跟不上，一般可以考虑同时增加 TiDB Server 和 TiKV Server 节点。</li></ul><h4 id="3-1-14-Percolator-用了分布式锁，crash-的客户端会保持锁，会造成锁没有-release？"><a href="#3-1-14-Percolator-用了分布式锁，crash-的客户端会保持锁，会造成锁没有-release？" class="headerlink" title="3.1.14 Percolator 用了分布式锁，crash 的客户端会保持锁，会造成锁没有 release？"></a>3.1.14 Percolator 用了分布式锁，crash 的客户端会保持锁，会造成锁没有 release？</h4><p>详细可参考 <a href="https://pingcap.com/blog-cn/percolator-and-txn/" target="_blank" rel="noopener">Percolator 和 TiDB 事务算法</a>。</p><h4 id="3-1-15-TiDB-为什么选用-gRPC-而不选用-Thrift，是因为-Google-在用吗？"><a href="#3-1-15-TiDB-为什么选用-gRPC-而不选用-Thrift，是因为-Google-在用吗？" class="headerlink" title="3.1.15 TiDB 为什么选用 gRPC 而不选用 Thrift，是因为 Google 在用吗？"></a>3.1.15 TiDB 为什么选用 gRPC 而不选用 Thrift，是因为 Google 在用吗？</h4><p>不只是因为 Google 在用，有一些比较好的特性我们需要，比如流控、加密还有 Streaming。</p><h4 id="3-1-16-like-bindo-customers-name-jason-92-这个92代表什么？"><a href="#3-1-16-like-bindo-customers-name-jason-92-这个92代表什么？" class="headerlink" title="3.1.16 like(bindo.customers.name, jason%, 92) 这个92代表什么？"></a>3.1.16 like(bindo.customers.name, jason%, 92) 这个92代表什么？</h4><p>那个是转义字符，默认是 (ASCII 92)。</p><h4 id="3-1-17-为什么-information-schema-tables-data-length-记录的大小和-TiKV-监控面板上的-store-size-不一样？"><a href="#3-1-17-为什么-information-schema-tables-data-length-记录的大小和-TiKV-监控面板上的-store-size-不一样？" class="headerlink" title="3.1.17 为什么 information_schema.tables.data_length 记录的大小和 TiKV 监控面板上的 store size 不一样？"></a>3.1.17 为什么 <code>information_schema.tables.data_length</code> 记录的大小和 TiKV 监控面板上的 store size 不一样？</h4><p>这是因为两者计算的角度不一样。<code>information_schema.tables.data_length</code> 是通过统计信息（平均每行的大小）得到的估算值。TiKV 监控面板上的 store size 是单个 TiKV 实例的数据文件（RocksDB 的 SST 文件）的大小总和。由于多版本和 TiKV 会压缩数据，所以两者显示的大小不一样。</p><h3 id="3-2-PD-管理"><a href="#3-2-PD-管理" class="headerlink" title="3.2 PD 管理"></a>3.2 PD 管理</h3><h4 id="3-2-1-访问-PD-报错：TiKV-cluster-is-not-bootstrapped"><a href="#3-2-1-访问-PD-报错：TiKV-cluster-is-not-bootstrapped" class="headerlink" title="3.2.1 访问 PD 报错：TiKV cluster is not bootstrapped"></a>3.2.1 访问 PD 报错：TiKV cluster is not bootstrapped</h4><p>PD 的大部分 API 需要在初始化 TiKV 集群以后才能使用，如果在部署新集群的时候只启动了 PD，还没有启动 TiKV，这时候访问 PD 就会报这个错误。遇到这个错误应该先把要部署的 TiKV 启动起来，TiKV 会自动完成初始化工作，然后就可以正常访问 PD。</p><h4 id="3-2-2-PD-启动报错：etcd-cluster-ID-mismatch"><a href="#3-2-2-PD-启动报错：etcd-cluster-ID-mismatch" class="headerlink" title="3.2.2 PD 启动报错：etcd cluster ID mismatch"></a>3.2.2 PD 启动报错：etcd cluster ID mismatch</h4><p>PD 启动参数中的 <code>--initial-cluster</code> 包含了某个不属于该集群的成员。遇到这个错误时请检查各个成员的所属集群，剔除错误的成员后即可正常启动。</p><h4 id="3-2-3-PD-能容忍的时间同步误差是多少？"><a href="#3-2-3-PD-能容忍的时间同步误差是多少？" class="headerlink" title="3.2.3 PD 能容忍的时间同步误差是多少？"></a>3.2.3 PD 能容忍的时间同步误差是多少？</h4><p>理论上，时间同步误差越小越好。PD 可容忍任意时长的误差，但是，时间同步误差越大意味着 PD 分配的时间戳与真实的物理时间相差越大，这个差距会影响读历史版本等功能。</p><h4 id="3-2-4-Client-连接是如何寻找-PD-的？"><a href="#3-2-4-Client-连接是如何寻找-PD-的？" class="headerlink" title="3.2.4 Client 连接是如何寻找 PD 的？"></a>3.2.4 Client 连接是如何寻找 PD 的？</h4><p>Client 连接只能通过 TiDB 访问集群，TiDB 负责连接 PD 与 TiKV，PD 与 TiKV 对 Client 透明。当 TiDB 连接任意一台 PD 的时候，PD 会告知 TiDB 当前的 leader 是谁，如果此台 PD 不是 leader，TiDB 将会重新连接至 leader PD。</p><h4 id="3-2-5-PD-参数中-leader-schedule-limit-和-region-schedule-limit-调度有什么区别？"><a href="#3-2-5-PD-参数中-leader-schedule-limit-和-region-schedule-limit-调度有什么区别？" class="headerlink" title="3.2.5 PD 参数中 leader-schedule-limit 和 region-schedule-limit 调度有什么区别？"></a>3.2.5 PD 参数中 leader-schedule-limit 和 region-schedule-limit 调度有什么区别？</h4><ul><li>leader-schedule-limit 调度是用来均衡不同 TiKV 的 leader 数，影响处理查询的负载。</li><li>region-schedule-limit 调度是均衡不同 TiKV 的副本数，影响不同节点的数据量。</li></ul><h4 id="3-2-6-每个-region-的-replica-数量可配置吗？调整的方法是？"><a href="#3-2-6-每个-region-的-replica-数量可配置吗？调整的方法是？" class="headerlink" title="3.2.6 每个 region 的 replica 数量可配置吗？调整的方法是？"></a>3.2.6 每个 region 的 replica 数量可配置吗？调整的方法是？</h4><p>可以，目前只能调整全局的 replica 数量。首次启动时 PD 会读配置文件（conf/pd.yml），使用其中的 max-replicas 配置，之后修改需要使用 pd-ctl 配置命令 <code>config set max-replicas $num</code>，配置后可通过 <code>config show all</code> 来查看已生效的配置。调整的时候，不会影响业务，会在后台添加，注意总 TiKV 实例数总是要大于等于设置的副本数，例如 3 副本需要至少 3 个 TiKV。增加副本数量之前需要预估额外的存储需求。pd-ctl 的详细用法可参考 <a href="/reference/tools/pd-control.md">PD Control 使用说明</a>。</p><h4 id="3-2-7-缺少命令行集群管理工具，整个集群的健康度当前是否正常，不好确认？"><a href="#3-2-7-缺少命令行集群管理工具，整个集群的健康度当前是否正常，不好确认？" class="headerlink" title="3.2.7 缺少命令行集群管理工具，整个集群的健康度当前是否正常，不好确认？"></a>3.2.7 缺少命令行集群管理工具，整个集群的健康度当前是否正常，不好确认？</h4><p>可以通过 pd-ctl 等工具来判断集群大概的状态，详细的集群状态还是需要通过监控来确认。</p><h4 id="3-2-8-集群下线节点后，怎么删除老集群节点监控信息？"><a href="#3-2-8-集群下线节点后，怎么删除老集群节点监控信息？" class="headerlink" title="3.2.8 集群下线节点后，怎么删除老集群节点监控信息？"></a>3.2.8 集群下线节点后，怎么删除老集群节点监控信息？</h4><p>下线节点一般指 TiKV 节点通过 pd-ctl 或者监控判断节点是否下线完成。节点下线完成后，手动停止下线节点上相关的服务。从 Prometheus 配置文件中删除对应节点的 node_exporter 信息。从 Ansible inventory.ini 中删除对应节点的信息。</p><h4 id="3-2-9-使用-PD-Control-连接-PD-Server-时，为什么只能通过本机-IP-连接，不能通过-127-0-0-1-连接？"><a href="#3-2-9-使用-PD-Control-连接-PD-Server-时，为什么只能通过本机-IP-连接，不能通过-127-0-0-1-连接？" class="headerlink" title="3.2.9 使用 PD Control 连接 PD Server 时，为什么只能通过本机 IP 连接，不能通过 127.0.0.1 连接？"></a>3.2.9 使用 PD Control 连接 PD Server 时，为什么只能通过本机 IP 连接，不能通过 127.0.0.1 连接？</h4><p>因为使用 TiDB Ansible 部署的集群，PD 对外服务端口不会绑定到 127.0.0.1，所以 PD Control 不会识别 127.0.0.1。</p><h3 id="3-3-TiDB-server-管理"><a href="#3-3-TiDB-server-管理" class="headerlink" title="3.3 TiDB server 管理"></a>3.3 TiDB server 管理</h3><h4 id="3-3-1-TiDB-的-lease-参数应该如何设置？"><a href="#3-3-1-TiDB-的-lease-参数应该如何设置？" class="headerlink" title="3.3.1 TiDB 的 lease 参数应该如何设置？"></a>3.3.1 TiDB 的 lease 参数应该如何设置？</h4><p>启动 TiDB Server 时，需要通过命令行参数设置 lease 参数（–lease=60），其值会影响 DDL 的速度（只会影响当前执行 DDL 的 session，其他的 session 不会受影响）。在测试阶段，lease 的值可以设为 1s，加快测试进度；在生产环境下，我们推荐这个值设为分钟级（一般可以设为 60），这样可以保证 DDL 操作的安全。</p><h4 id="3-3-2-DDL-在正常情况下的耗时是多少？"><a href="#3-3-2-DDL-在正常情况下的耗时是多少？" class="headerlink" title="3.3.2 DDL 在正常情况下的耗时是多少？"></a>3.3.2 DDL 在正常情况下的耗时是多少？</h4><p>一般情况下处理一个 DDL 操作（之前没有其他 DDL 操作在处理）的耗时基本可以分如下为三种：</p><ul><li>add index 操作，且此操作对应表数据行数比较少，耗时约为 3s。</li><li>add index 操作，且此操作对应表数据行数比较多，耗时具体由表中数据行数和当时 QPS 情况定（add index 操作优先级比一般 SQL 低）。</li><li>其他 DDL 操作耗时约为 1s。</li></ul><p>此外，如果接收 DDL 请求的 TiDB 和 DDL owner 所处的 TiDB 是一台，那么上面列举的第一和第三种可能的耗时应该在几十到几百毫秒。</p><h4 id="3-3-3-为什么有的时候执行-DDL-会很慢？"><a href="#3-3-3-为什么有的时候执行-DDL-会很慢？" class="headerlink" title="3.3.3 为什么有的时候执行 DDL 会很慢？"></a>3.3.3 为什么有的时候执行 DDL 会很慢？</h4><p>可能原因如下：</p><ul><li>多个 DDL 语句一起执行的时候，后面的几个 DDL 语句会比较慢。原因是当前 TiDB 集群中 DDL 操作是串行执行的。</li><li>在正常集群启动后，第一个 DDL 操作的执行时间可能会比较久，一般在 30s 左右，这个原因是刚启动时 TiDB 在竞选处理 DDL 的 leader。</li><li>由于停 TiDB 时不能与 PD 正常通信（包括停电情况）或者用 <code>kill -9</code> 指令停 TiDB 导致 TiDB 没有及时从 PD 清理注册数据，那么会影响 TiDB 启动后 10min 内的 DDL 语句处理时间。这段时间内运行 DDL 语句时，每个 DDL 状态变化都需要等待 2 * lease（默认 lease = 45s）。</li><li>当集群中某个 TiDB 与 PD 之间发生通信问题，即 TiDB 不能从 PD 及时获取或更新版本信息，那么这时候 DDL 操作的每个状态处理需要等待 2 * lease。</li></ul><h4 id="3-3-4-TiDB-可以使用-S3-作为后端存储吗？"><a href="#3-3-4-TiDB-可以使用-S3-作为后端存储吗？" class="headerlink" title="3.3.4 TiDB 可以使用 S3 作为后端存储吗？"></a>3.3.4 TiDB 可以使用 S3 作为后端存储吗？</h4><p>不可以，目前 TiDB 只支持分布式存储引擎和 GolevelDB/RocksDB/BoltDB 引擎。</p><h4 id="3-3-5-Information-schema-能否支持更多真实信息？"><a href="#3-3-5-Information-schema-能否支持更多真实信息？" class="headerlink" title="3.3.5 Information_schema 能否支持更多真实信息？"></a>3.3.5 Information_schema 能否支持更多真实信息？</h4><p>Information_schema 库里面的表主要是为了兼容 MySQL 而存在，有些第三方软件会查询里面的信息。在目前 TiDB 的实现中，里面大部分只是一些空表。后续随着 TiDB 的升级，会提供更多的参数信息。当前 TiDB 支持的 Information_schema 请参考 <a href="/reference/system-databases/information-schema.md">TiDB 系统数据库说明文档</a>。</p><h4 id="3-3-6-TiDB-Backoff-type-主要原因"><a href="#3-3-6-TiDB-Backoff-type-主要原因" class="headerlink" title="3.3.6 TiDB Backoff type 主要原因?"></a>3.3.6 TiDB Backoff type 主要原因?</h4><p>TiDB-server 与 TiKV-server 随时进行通信，在进行大量数据操作过程中，会出现 <code>Server is busy</code> 或者 <code>backoff.maxsleep 20000ms</code> 的日志提示信息，这是由于 TiKV-server 在处理过程中系统比较忙而出现的提示信息，通常这时候可以通过系统资源监控到 TiKV 主机系统资源使用率比较高的情况出现。如果这种情况出现，可以根据资源使用情况进行相应的扩容操作。</p><h4 id="3-3-7-TiDB-TiClient-type-主要原因？"><a href="#3-3-7-TiDB-TiClient-type-主要原因？" class="headerlink" title="3.3.7 TiDB TiClient type 主要原因？"></a>3.3.7 TiDB TiClient type 主要原因？</h4><p>TiClient Region Error 该指标描述的是在 TiDB-server 作为客户端通过 KV 接口访问 TiKV-server 进行数据操作过程中，TiDB-server 操作 TiKV-server 中的 Region 数据出现的错误类型与 metric 指标，错误类型包括 not_leader、stale_epoch。出现这些错误的情况是当 TiDB-server 根据自己的缓存信息去操作 Region leader 数据的时候，Region leader 发生了迁移或者 TiKV 当前的 Region 信息与 TiDB 缓存的路由信息不一致而出现的错误提示。一般这种情况下，TiDB-server 都会自动重新从 PD 获取最新的路由数据，重做之前的操作。</p><h4 id="3-3-8-TiDB-同时支持的最大并发连接数？"><a href="#3-3-8-TiDB-同时支持的最大并发连接数？" class="headerlink" title="3.3.8 TiDB 同时支持的最大并发连接数？"></a>3.3.8 TiDB 同时支持的最大并发连接数？</h4><p>当前版本 TiDB 没有最大连接数的限制，如果并发过大导致响应时间增加，可以通过增加 TiDB 节点进行扩容。</p><h4 id="3-3-9-如何查看某张表创建的时间？"><a href="#3-3-9-如何查看某张表创建的时间？" class="headerlink" title="3.3.9 如何查看某张表创建的时间？"></a>3.3.9 如何查看某张表创建的时间？</h4><p>information_schema 库中的 tables 表里的 create_time 即为表的真实创建时间。</p><h4 id="3-3-9-TiDB-的日志中-EXPENSIVE-QUERY-是什么意思？"><a href="#3-3-9-TiDB-的日志中-EXPENSIVE-QUERY-是什么意思？" class="headerlink" title="3.3.9 TiDB 的日志中 EXPENSIVE_QUERY 是什么意思？"></a>3.3.9 TiDB 的日志中 EXPENSIVE_QUERY 是什么意思？</h4><p>TiDB 在执行 SQL 时，预估出来每个 operator 处理了超过 10000 条数据就认为这条 query 是 expensive query。可以通过修改 tidb-server 配置参数来对这个门限值进行调整，调整后需要重新启动 tidb-server。</p><h4 id="3-3-10-在-TiDB-中如何控制或改变-SQL-提交的执行优先级？"><a href="#3-3-10-在-TiDB-中如何控制或改变-SQL-提交的执行优先级？" class="headerlink" title="3.3.10 在 TiDB 中如何控制或改变 SQL 提交的执行优先级？"></a>3.3.10 在 TiDB 中如何控制或改变 SQL 提交的执行优先级？</h4><p>TiDB 支持改变 <a href="/reference/configuration/tidb-server/tidb-specific-variables.md#tidb_force_priority">per-session</a>、<a href="/reference/configuration/tidb-server/configuration-file.md#force-priority">全局</a>或单个语句的优先级。优先级包括：</p><ul><li>HIGH_PRIORITY：该语句为高优先级语句，TiDB 在执行阶段会优先处理这条语句</li><li>LOW_PRIORITY：该语句为低优先级语句，TiDB 在执行阶段会降低这条语句的优先级</li></ul><p>以上两种参数可以结合 TiDB 的 DML 语言进行使用，使用方法举例如下：</p><ol><li><p>通过在数据库中写 SQL 的方式来调整优先级：</p><p>  copyable “sql” </p> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">HIGH_PRIORITY</span> | <span class="keyword">LOW_PRIORITY</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> table_name;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">HIGH_PRIORITY</span> | <span class="keyword">LOW_PRIORITY</span> <span class="keyword">into</span> table_name insert_values;</span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">HIGH_PRIORITY</span> | <span class="keyword">LOW_PRIORITY</span> <span class="keyword">from</span> table_name;</span><br><span class="line"><span class="keyword">update</span> <span class="keyword">HIGH_PRIORITY</span> | <span class="keyword">LOW_PRIORITY</span> table_reference <span class="keyword">set</span> assignment_list <span class="keyword">where</span> where_condition;</span><br><span class="line"><span class="keyword">replace</span> <span class="keyword">HIGH_PRIORITY</span> | <span class="keyword">LOW_PRIORITY</span> <span class="keyword">into</span> table_name;</span><br></pre></td></tr></table></figure></li><li><p>全表扫会自动调整为低优先级，analyze 也是默认低优先级。</p></li></ol><h4 id="3-3-11-在-TiDB-中-auto-analyze-的触发策略是怎样的？"><a href="#3-3-11-在-TiDB-中-auto-analyze-的触发策略是怎样的？" class="headerlink" title="3.3.11 在 TiDB 中 auto analyze 的触发策略是怎样的？"></a>3.3.11 在 TiDB 中 auto analyze 的触发策略是怎样的？</h4><p>触发策略：新表达到 1000 条，并且在 1 分钟内没有写入，会自动触发。</p><p>当表的（修改数/当前总行数）大于 <code>tidb_auto_analyze_ratio</code> 的时候，会自动触发 <code>analyze</code> 语句。<code>tidb_auto_analyze_ratio</code> 的默认值为 0.5，即默认开启此功能。为了保险起见，在开启此功能的时候，保证了其最小值为 0.3。但是不能大于等于 <code>pseudo-estimate-ratio</code>（默认值为 0.8），否则会有一段时间使用 pseudo 统计信息，建议设置值为 0.5。</p><h4 id="3-3-12-SQL-中如何通过-hint-使用一个具体的-index？"><a href="#3-3-12-SQL-中如何通过-hint-使用一个具体的-index？" class="headerlink" title="3.3.12 SQL 中如何通过 hint 使用一个具体的 index？"></a>3.3.12 SQL 中如何通过 hint 使用一个具体的 index？</h4><p>同 MySQL 的用法一致，例如：<br><code>select column_name from table_name use index（index_name）where where_condition;</code></p><h4 id="3-3-13-触发-Information-schema-is-changed-错误的原因？"><a href="#3-3-13-触发-Information-schema-is-changed-错误的原因？" class="headerlink" title="3.3.13 触发 Information schema is changed 错误的原因？"></a>3.3.13 触发 Information schema is changed 错误的原因？</h4><p>TiDB 在执行 SQL 语句时，会使用当时的 <code>schema</code> 来处理该 SQL 语句，而且 TiDB 支持在线异步变更 DDL。那么，在执行 DML 的时候可能有 DDL 语句也在执行，而你需要确保每个 SQL 语句在同一个 <code>schema</code> 上执行。所以当执行 DML 时，遇到正在执行中的 DDL 操作就可能会报 <code>Information schema is changed</code> 的错误。为了避免太多的 DML 语句报错，已做了一些优化。</p><p>现在会报此错的可能原因如下（后两个报错原因与表无关）：</p><ul><li>执行的 DML 语句中涉及的表和集群中正在执行的 DDL 的表有相同的，那么这个 DML 语句就会报此错。</li><li>这个 DML 执行时间很久，而这段时间内执行了很多 DDL 语句，导致中间 <code>schema</code> 版本变更次数超过 1024 （此为默认值，可以通过 <code>tidb_max_delta_schema_count</code> 变量修改）。</li><li>接受 DML 请求的 TiDB 长时间不能加载到 <code>schema information</code>（TiDB 与 PD 或 TiKV 之间的网络连接故障等会导致此问题），而这段时间内执行了很多 DDL 语句，导致中间 <code>schema</code> 版本变更次数超过 100。</li></ul><blockquote><p><strong>注意：</strong></p><ul><li>目前 TiDB 未缓存所有的 <code>schema</code> 版本信息。</li><li>对于每个 DDL 操作，<code>schema</code> 版本变更的数量与对应 <code>schema state</code> 变更的次数一致。</li><li>不同的 DDL 操作版本变更次数不一样。例如，<code>create table</code> 操作会有 1 次 <code>schema</code> 版本变更；<code>add column</code> 操作有 4 次 <code>schema</code> 版本变更。</li></ul></blockquote><h4 id="3-3-14-触发-Information-schema-is-out-of-date-错误的原因？"><a href="#3-3-14-触发-Information-schema-is-out-of-date-错误的原因？" class="headerlink" title="3.3.14 触发 Information schema is out of date 错误的原因？"></a>3.3.14 触发 Information schema is out of date 错误的原因？</h4><p>当执行 DML 时，TiDB 超过一个 DDL lease 时间（默认 45s）没能加载到最新的 schema 就可能会报 <code>Information schema is out of date</code> 的错误。遇到此错的可能原因如下：</p><ul><li>执行此 DML 的 TiDB 被 kill 后准备退出，且此 DML 对应的事务执行时间超过一个 DDL lease，在事务提交时会报这个错误。</li><li>TiDB 在执行此 DML 时，有一段时间内连不上 PD 或者 TiKV，导致 TiDB 超过一个 DDL lease 时间没有 load schema，或者导致 TiDB 断开与 PD 之间带 keep alive 设置的连接。</li></ul><h4 id="3-3-15-高并发情况下执行-DDL-时报错的原因？"><a href="#3-3-15-高并发情况下执行-DDL-时报错的原因？" class="headerlink" title="3.3.15 高并发情况下执行 DDL 时报错的原因？"></a>3.3.15 高并发情况下执行 DDL 时报错的原因？</h4><p>高并发情况下执行 DDL（比如批量建表）时，极少部分 DDL 可能会由于并发执行时 key 冲突而执行失败。</p><p>并发执行 DDL 时，建议将 DDL 数量保持在 20 以下，否则你需要在应用端重试失败的 DDL 语句。</p><h3 id="3-4-TiKV-管理"><a href="#3-4-TiKV-管理" class="headerlink" title="3.4 TiKV 管理"></a>3.4 TiKV 管理</h3><h4 id="3-4-1-TiKV-集群副本建议配置数量是多少，是不是最小高可用配置（3个）最好？"><a href="#3-4-1-TiKV-集群副本建议配置数量是多少，是不是最小高可用配置（3个）最好？" class="headerlink" title="3.4.1 TiKV 集群副本建议配置数量是多少，是不是最小高可用配置（3个）最好？"></a>3.4.1 TiKV 集群副本建议配置数量是多少，是不是最小高可用配置（3个）最好？</h4><p>如果是测试环境 3 副本足够；在生产环境中，不可让集群副本数低于 3，需根据架构特点、业务系统及恢复能力的需求，适当增加副本数。值得注意的是，副本升高，性能会有下降，但是安全性更高。</p><h4 id="3-4-2-TiKV-启动报错：cluster-ID-mismatch"><a href="#3-4-2-TiKV-启动报错：cluster-ID-mismatch" class="headerlink" title="3.4.2 TiKV 启动报错：cluster ID mismatch"></a>3.4.2 TiKV 启动报错：cluster ID mismatch</h4><p>TiKV 本地存储的 cluster ID 和指定的 PD 的 cluster ID 不一致。在部署新的 PD 集群的时候，PD 会随机生成一个 cluster ID，TiKV 第一次初始化的时候会从 PD 获取 cluster ID 存储在本地，下次启动的时候会检查本地的 cluster ID 与 PD 的 cluster ID 是否一致，如果不一致则会报错并退出。出现这个错误一个常见的原因是，用户原先部署了一个集群，后来把 PD 的数据删除了并且重新部署了新的 PD，但是 TiKV 还是使用旧的数据重启连到新的 PD 上，就会报这个错误。</p><h4 id="3-4-3-TiKV-启动报错：duplicated-store-address"><a href="#3-4-3-TiKV-启动报错：duplicated-store-address" class="headerlink" title="3.4.3 TiKV 启动报错：duplicated store address"></a>3.4.3 TiKV 启动报错：duplicated store address</h4><p>启动参数中的地址已经被其他的 TiKV 注册在 PD 集群中了。造成该错误的常见情况：TiKV <code>--data-dir</code> 指定的路径下没有数据文件夹（删除或移动后没有更新 –data-dir），用之前参数重新启动该 TiKV。请尝试用 pd-ctl 的 <a href="https://github.com/pingcap/pd/tree/55db505e8f35e8ab4e00efd202beb27a8ecc40fb/tools/pd-ctl#store-delete--label--weight-store_id----jqquery-string" target="_blank" rel="noopener">store delete</a> 功能，删除之前的 store，然后重新启动 TiKV 即可。</p><h4 id="3-4-4-TiKV-master-和-slave-用的是一样的压缩算法，为什么效果不一样"><a href="#3-4-4-TiKV-master-和-slave-用的是一样的压缩算法，为什么效果不一样" class="headerlink" title="3.4.4 TiKV master 和 slave 用的是一样的压缩算法，为什么效果不一样?"></a>3.4.4 TiKV master 和 slave 用的是一样的压缩算法，为什么效果不一样?</h4><p>目前来看 master 有些文件的压缩率会高一些，这个取决于底层数据的分布和 RocksDB 的实现，数据大小偶尔有些波动是正常的，底层存储引擎会根据需要调整数据。</p><h4 id="3-4-5-TiKV-block-cache-有哪些特性？"><a href="#3-4-5-TiKV-block-cache-有哪些特性？" class="headerlink" title="3.4.5 TiKV block cache 有哪些特性？"></a>3.4.5 TiKV block cache 有哪些特性？</h4><p>TiKV 使用了 RocksDB 的 Column Family (CF) 特性，KV 数据最终存储在默认 RocksDB 内部的 default、write、lock 3 个 CF 内。</p><ul><li>default CF 存储的是真正的数据，与其对应的参数位于 <code>[rocksdb.defaultcf]</code> 项中。</li><li>write CF 存储的是数据的版本信息（MVCC）、索引、小表相关的数据，相关的参数位于 <code>[rocksdb.writecf]</code> 项中。</li><li>lock CF 存储的是锁信息，系统使用默认参数。</li><li>Raft RocksDB 实例存储 Raft log。default CF 主要存储的是 Raft log，与其对应的参数位于 <code>[raftdb.defaultcf]</code> 项中。</li><li>所有 CF 共享一个 Block-cache，用于缓存数据块，加速 RocksDB 的读取速度，Block-cache 的大小通过参数 <code>block-cache-size</code> 控制，<code>block-cache-size</code> 越大，能够缓存的热点数据越多，对读取操作越有利，同时占用的系统内存也会越多。</li><li>每个 CF 有各自的 Write-buffer，大小通过 <code>write-buffer-size</code> 控制。</li></ul><h4 id="3-4-6-TiKV-channel-full-是什么原因？"><a href="#3-4-6-TiKV-channel-full-是什么原因？" class="headerlink" title="3.4.6 TiKV channel full 是什么原因？"></a>3.4.6 TiKV channel full 是什么原因？</h4><ul><li>Raftstore 线程太忙，或者因 I/O 而卡住。可以看一下 Raftstore 的 CPU 使用情况。</li><li>TiKV 过忙（CPU、磁盘 I/O 等），请求处理不过来。</li></ul><h4 id="3-4-7-TiKV-频繁切换-Region-leader-是什么原因？"><a href="#3-4-7-TiKV-频繁切换-Region-leader-是什么原因？" class="headerlink" title="3.4.7 TiKV 频繁切换 Region leader 是什么原因？"></a>3.4.7 TiKV 频繁切换 Region leader 是什么原因？</h4><ul><li>网络问题导致节点间通信卡了，查看 Report failures 监控。</li><li>原主 Leader 的节点卡了，导致没有及时给 Follower 发送消息。</li><li>Raftstore 线程卡了。</li></ul><h4 id="3-4-8-如果一个节点挂了会影响服务吗？影响会持续多久？"><a href="#3-4-8-如果一个节点挂了会影响服务吗？影响会持续多久？" class="headerlink" title="3.4.8 如果一个节点挂了会影响服务吗？影响会持续多久？"></a>3.4.8 如果一个节点挂了会影响服务吗？影响会持续多久？</h4><p>TiDB 使用 Raft 在多个副本之间做数据同步（默认为每个 Region 3 个副本）。当一份备份出现问题时，其他的副本能保证数据的安全。根据 Raft 协议，当某个节点挂掉导致该节点里的 Leader 失效时，在最大 2 * lease time（leasetime 是 10 秒）时间后，通过 Raft 协议会很快将一个另外一个节点里的 Follower 选为新的 Region Leader 来提供服务。</p><h4 id="3-4-9-TiKV-在分别在那些场景下占用大量-IO、内存、CPU（超过参数配置的多倍）？"><a href="#3-4-9-TiKV-在分别在那些场景下占用大量-IO、内存、CPU（超过参数配置的多倍）？" class="headerlink" title="3.4.9 TiKV 在分别在那些场景下占用大量 IO、内存、CPU（超过参数配置的多倍）？"></a>3.4.9 TiKV 在分别在那些场景下占用大量 IO、内存、CPU（超过参数配置的多倍）？</h4><p>在大量写入、读取的场景中会占用大量的磁盘 IO、内存、CPU。在执行很复杂的查询，比如会产生很大中间结果集的情况下，会消耗很多的内存和 CPU 资源。</p><h4 id="3-4-10-TiKV-是否可以使用-SAS-SATA-盘或者进行-SSD-SAS-混合部署？"><a href="#3-4-10-TiKV-是否可以使用-SAS-SATA-盘或者进行-SSD-SAS-混合部署？" class="headerlink" title="3.4.10 TiKV 是否可以使用 SAS/SATA 盘或者进行 SSD/SAS 混合部署？"></a>3.4.10 TiKV 是否可以使用 SAS/SATA 盘或者进行 SSD/SAS 混合部署？</h4><p>不可以使用，TiDB 在进行 OLTP 场景中，数据访问和操作需要高 IO 磁盘的支持，TiDB 作为强一致的分布式数据库，存在一定的写放大，如副本复制、存储底层 Compaction，因此，TiDB 部署的最佳实践中推荐用户使用 NVMe SSD 磁盘作为数据存储磁盘。另外，TiKV 与 PD 不能混合部署。</p><h4 id="3-4-11-数据表-Key-的-Range-范围划分是在数据接入之前就已经划分好了吗？"><a href="#3-4-11-数据表-Key-的-Range-范围划分是在数据接入之前就已经划分好了吗？" class="headerlink" title="3.4.11 数据表 Key 的 Range 范围划分是在数据接入之前就已经划分好了吗？"></a>3.4.11 数据表 Key 的 Range 范围划分是在数据接入之前就已经划分好了吗？</h4><p>不是的，这个和 MySQL 分表规则不一样，需要提前设置好，TiKV 是根据 Region 的大小动态分裂的。</p><h4 id="3-4-12-Region-是如何进行分裂的？"><a href="#3-4-12-Region-是如何进行分裂的？" class="headerlink" title="3.4.12 Region 是如何进行分裂的？"></a>3.4.12 Region 是如何进行分裂的？</h4><p>Region 不是前期划分好的，但确实有 Region 分裂机制。当 Region 的大小超过参数 <code>region-max-size</code> 或 <code>region-max-keys</code> 的值时，就会触发分裂，分裂后的信息会汇报给 PD。</p><h4 id="3-4-13-TiKV-是否有类似-MySQL-的-innodb-flush-log-trx-commit-参数，来保证提交数据不丢失？"><a href="#3-4-13-TiKV-是否有类似-MySQL-的-innodb-flush-log-trx-commit-参数，来保证提交数据不丢失？" class="headerlink" title="3.4.13 TiKV 是否有类似 MySQL 的 innodb_flush_log_trx_commit 参数，来保证提交数据不丢失？"></a>3.4.13 TiKV 是否有类似 MySQL 的 <code>innodb_flush_log_trx_commit</code> 参数，来保证提交数据不丢失？</h4><p>是的，TiKV 单机的存储引擎目前使用两个 RocksDB 实例，其中一个存储 raft-log，TiKV 有个 sync-log 参数，在 ture 的情况下，每次提交都会强制刷盘到 raft-log，如果发生 crash 后，通过 raft-log 进行 KV 数据的恢复。</p><h4 id="3-4-14-对-WAL-存储有什么推荐的硬件配置，例如-SSD，RAID-级别，RAID-卡-cache-策略，NUMA-设置，文件系统选择，操作系统的-IO-调度策略等？"><a href="#3-4-14-对-WAL-存储有什么推荐的硬件配置，例如-SSD，RAID-级别，RAID-卡-cache-策略，NUMA-设置，文件系统选择，操作系统的-IO-调度策略等？" class="headerlink" title="3.4.14 对 WAL 存储有什么推荐的硬件配置，例如 SSD，RAID 级别，RAID 卡 cache 策略，NUMA 设置，文件系统选择，操作系统的 IO 调度策略等？"></a>3.4.14 对 WAL 存储有什么推荐的硬件配置，例如 SSD，RAID 级别，RAID 卡 cache 策略，NUMA 设置，文件系统选择，操作系统的 IO 调度策略等？</h4><p>WAL 属于顺序写，目前我们并没有单独对他进行配置，建议 SSD，RAID 如果允许的话，最好是 RAID 10，RAID 卡 cache、操作系统 I/O 调度目前没有针对性的最佳实践，Linux 7 以上默认配置即可，NUMA 没有特别建议，NUMA 内存分配策略可以尝试使用 <code>interleave = all</code>，文件系统建议 ext4。</p><h4 id="3-4-15-在最严格的-sync-log-true-数据可用模式下，写入性能如何？"><a href="#3-4-15-在最严格的-sync-log-true-数据可用模式下，写入性能如何？" class="headerlink" title="3.4.15 在最严格的 sync-log = true 数据可用模式下，写入性能如何？"></a>3.4.15 在最严格的 <code>sync-log = true</code> 数据可用模式下，写入性能如何？</h4><p>一般来说，开启 <code>sync-log</code> 会让性能损耗 30% 左右。关闭 <code>sync-log</code> 时的性能表现，请参见 <a href="/benchmark/sysbench-v4.md">TiDB Sysbench 性能测试报告</a>。</p><h4 id="3-4-16-是否可以利用-TiKV-的-Raft-多副本达到完全的数据可靠，单机存储引擎是否需要最严格模式？"><a href="#3-4-16-是否可以利用-TiKV-的-Raft-多副本达到完全的数据可靠，单机存储引擎是否需要最严格模式？" class="headerlink" title="3.4.16 是否可以利用 TiKV 的 Raft + 多副本达到完全的数据可靠，单机存储引擎是否需要最严格模式？"></a>3.4.16 是否可以利用 TiKV 的 Raft + 多副本达到完全的数据可靠，单机存储引擎是否需要最严格模式？</h4><p>通过使用 <a href="https://raft.github.io/" target="_blank" rel="noopener">Raft 一致性算法</a>，数据在各 TiKV 节点间复制为多副本，以确保某个节点挂掉时数据的安全性。只有当数据已写入超过 50% 的副本时，应用才返回 ACK（三副本中的两副本）。但理论上两个节点也可能同时发生故障，所以除非是对性能要求高于数据安全的场景，一般都强烈推荐开启 <code>sync-log</code>。</p><p>另外，还有一种 <code>sync-log</code> 的替代方案，即在 Raft group 中用五个副本而非三个。这将允许两个副本同时发生故障，而仍然能保证数据安全性。</p><p>对于单机存储引擎也同样推荐打开 <code>sync-log</code> 模式。否则如果节点宕机可能会丢失最后一次写入数据。</p><h4 id="3-4-17-使用-Raft-协议，数据写入会有多次网络的-roundtrip，实际写入延迟如何？"><a href="#3-4-17-使用-Raft-协议，数据写入会有多次网络的-roundtrip，实际写入延迟如何？" class="headerlink" title="3.4.17 使用 Raft 协议，数据写入会有多次网络的 roundtrip，实际写入延迟如何？"></a>3.4.17 使用 Raft 协议，数据写入会有多次网络的 roundtrip，实际写入延迟如何？</h4><p>理论上，和单机数据库相比，数据写入会多四个网络延迟。</p><h4 id="3-4-18-有没有类似-MySQL-的-InnoDB-Memcached-plugin，可以直接使用-KV-接口，可以不需要独立的-Cache？"><a href="#3-4-18-有没有类似-MySQL-的-InnoDB-Memcached-plugin，可以直接使用-KV-接口，可以不需要独立的-Cache？" class="headerlink" title="3.4.18 有没有类似 MySQL 的 InnoDB Memcached plugin，可以直接使用 KV 接口，可以不需要独立的 Cache？"></a>3.4.18 有没有类似 MySQL 的 InnoDB Memcached plugin，可以直接使用 KV 接口，可以不需要独立的 Cache？</h4><p>TiKV 支持单独进行接口调用，理论上也可以起个实例做为 Cache，但 TiDB 最大的价值是分布式关系型数据库，我们原则上不对 TiKV 单独进行支持。</p><h4 id="3-4-19-Coprocessor-组件的主要作用？"><a href="#3-4-19-Coprocessor-组件的主要作用？" class="headerlink" title="3.4.19 Coprocessor 组件的主要作用？"></a>3.4.19 Coprocessor 组件的主要作用？</h4><ul><li>减少 TiDB 与 TiKV 之间的数据传输。</li><li>计算下推，充分利用 TiKV 的分布式计算资源。</li></ul><h4 id="3-4-20-IO-error-No-space-left-on-device-While-appending-to-file"><a href="#3-4-20-IO-error-No-space-left-on-device-While-appending-to-file" class="headerlink" title="3.4.20 IO error: No space left on device While appending to file"></a>3.4.20 IO error: No space left on device While appending to file</h4><p>这是磁盘空间不足导致的，需要加节点或者扩大磁盘空间。</p><h4 id="3-4-21-为什么-TiKV-容易出现-OOM？"><a href="#3-4-21-为什么-TiKV-容易出现-OOM？" class="headerlink" title="3.4.21 为什么 TiKV 容易出现 OOM？"></a>3.4.21 为什么 TiKV 容易出现 OOM？</h4><p>TiKV 的内存占用主要来自于 RocksDB 的 block-cache，默认为系统总内存的 40%。当 TiKV 容易出现 OOM 时，检查 <code>block-cache-size</code> 配置是否过高。还需要注意，当单机部署了多个 TiKV 实例时，需要显式地配置该参数，以防止多个实例占用过多系统内存导致 OOM。</p><h4 id="3-4-22-TiDB-数据和-RawKV-数据可存储于同一个-TiKV-集群里吗？"><a href="#3-4-22-TiDB-数据和-RawKV-数据可存储于同一个-TiKV-集群里吗？" class="headerlink" title="3.4.22 TiDB 数据和 RawKV 数据可存储于同一个 TiKV 集群里吗？"></a>3.4.22 TiDB 数据和 RawKV 数据可存储于同一个 TiKV 集群里吗？</h4><p>不可以。TiDB 数据（或使用其他事务 API 生成的数据）依赖于一种特殊的键值格式，和 RawKV API 数据（或其他基于 RawKV 的服务生成的数据）并不兼容。</p><h3 id="3-5-TiDB-测试"><a href="#3-5-TiDB-测试" class="headerlink" title="3.5 TiDB 测试"></a>3.5 TiDB 测试</h3><h4 id="3-5-1-TiDB-Sysbench-基准测试结果如何？"><a href="#3-5-1-TiDB-Sysbench-基准测试结果如何？" class="headerlink" title="3.5.1 TiDB Sysbench 基准测试结果如何？"></a>3.5.1 TiDB Sysbench 基准测试结果如何？</h4><p>很多用户在接触 TiDB 都习惯做一个基准测试或者 TiDB 与 MySQL 的对比测试，官方也做了一个类似测试，汇总很多测试结果后，我们发现虽然测试的数据有一定的偏差，但结论或者方向基本一致，由于 TiDB 与 MySQL 由于架构上的差别非常大，很多方面是很难找到一个基准点，所以官方的建议两点：</p><ul><li>大家不要用过多精力纠结这类基准测试上，应该更多关注 TiDB 的场景上的区别。</li><li>大家可以直接参考 <a href="/benchmark/sysbench-v4.md">TiDB Sysbench 性能测试报告</a>。</li></ul><h4 id="3-5-2-TiDB-集群容量-QPS-与节点数之间关系如何，和-MySQL-对比如何？"><a href="#3-5-2-TiDB-集群容量-QPS-与节点数之间关系如何，和-MySQL-对比如何？" class="headerlink" title="3.5.2 TiDB 集群容量 QPS 与节点数之间关系如何，和 MySQL 对比如何？"></a>3.5.2 TiDB 集群容量 QPS 与节点数之间关系如何，和 MySQL 对比如何？</h4><ul><li>在 10 节点内，TiDB 写入能力（Insert TPS）和节点数量基本成 40% 线性递增，MySQL 由于是单节点写入，所以不具备写入扩展能力。</li><li>MySQL 读扩容可以通过添加从库进行扩展，但写流量无法扩展，只能通过分库分表，而分库分表有很多问题，具体参考<a href="http://t.cn/RTD18qV" target="_blank" rel="noopener">方案虽好，成本先行：数据库 Sharding+Proxy 实践解析</a>。</li><li>TiDB 不管是读流量、还是写流量都可以通过添加节点快速方便的进行扩展。</li></ul><h4 id="3-5-3-我们的-DBA-测试过-MySQL-性能，单台-TiDB-的性能没有-MySQL-性能那么好？"><a href="#3-5-3-我们的-DBA-测试过-MySQL-性能，单台-TiDB-的性能没有-MySQL-性能那么好？" class="headerlink" title="3.5.3 我们的 DBA 测试过 MySQL 性能，单台 TiDB 的性能没有 MySQL 性能那么好？"></a>3.5.3 我们的 DBA 测试过 MySQL 性能，单台 TiDB 的性能没有 MySQL 性能那么好？</h4><p>TiDB 设计的目标就是针对 MySQL 单台容量限制而被迫做的分库分表的场景，或者需要强一致性和完整分布式事务的场景。它的优势是通过尽量下推到存储节点进行并行计算。对于小表（比如千万级以下），不适合 TiDB，因为数据量少，Region 有限，发挥不了并行的优势，最极端的就是计数器表，几行记录高频更新，这几行在 TiDB 里，会变成存储引擎上的几个 KV，然后只落在一个 Region 里，而这个 Region 只落在一个节点上。加上后台强一致性复制的开销，TiDB 引擎到 TiKV 引擎的开销，最后表现出来的就是没有单个 MySQL 好。</p><h3 id="3-6-TiDB-备份恢复"><a href="#3-6-TiDB-备份恢复" class="headerlink" title="3.6 TiDB 备份恢复"></a>3.6 TiDB 备份恢复</h3><h4 id="3-6-1-TiDB-主要备份方式？"><a href="#3-6-1-TiDB-主要备份方式？" class="headerlink" title="3.6.1 TiDB 主要备份方式？"></a>3.6.1 TiDB 主要备份方式？</h4><p>目前，推荐的备份方式是使用 <a href="/reference/tools/mydumper.md">PingCAP fork 的 Mydumper</a>。尽管 TiDB 也支持使用 MySQL 官方工具 <code>mysqldump</code> 进行数据备份、恢复，但其性能低于 <a href="/reference/tools/mydumper.md"><code>mydumper</code></a>/<a href="/reference/tools/loader.md"><code>loader</code></a>，并且该工具备份、恢复大量数量时，要耗费更多时间。</p><p>使用 Mydumper 导出来的数据文件尽可能的小, 最好不要超过 64M, 可以设置参数 -F 64；</p><p>loader 的 -t 参数可以根据 TiKV 的实例个数以及负载进行评估调整，例如 3 个 TiKV 的场景， 此值可以设为 3 * (1 ～ n)，当 TiKV 负载过高，loader 以及 TiDB 日志中出现大量 <code>backoffer.maxSleep 15000ms is exceeded</code> 可以适当调小该值，当 TiKV 负载不是太高的时候，可以适当调大该值。</p><h2 id="四、数据、流量迁移"><a href="#四、数据、流量迁移" class="headerlink" title="四、数据、流量迁移"></a>四、数据、流量迁移</h2><h3 id="4-1-全量数据导出导入"><a href="#4-1-全量数据导出导入" class="headerlink" title="4.1 全量数据导出导入"></a>4.1 全量数据导出导入</h3><h4 id="4-1-1-Mydumper"><a href="#4-1-1-Mydumper" class="headerlink" title="4.1.1 Mydumper"></a>4.1.1 Mydumper</h4><p>参见 <a href="/reference/tools/mydumper.md">Mydumper 使用文档</a>。</p><h4 id="4-1-2-Loader"><a href="#4-1-2-Loader" class="headerlink" title="4.1.2 Loader"></a>4.1.2 Loader</h4><p>参见 <a href="/reference/tools/loader.md">Loader 使用文档</a>。</p><h4 id="4-1-3-如何将一个运行在-MySQL-上的应用迁移到-TiDB-上？"><a href="#4-1-3-如何将一个运行在-MySQL-上的应用迁移到-TiDB-上？" class="headerlink" title="4.1.3 如何将一个运行在 MySQL 上的应用迁移到 TiDB 上？"></a>4.1.3 如何将一个运行在 MySQL 上的应用迁移到 TiDB 上？</h4><p>TiDB 支持绝大多数 MySQL 语法，一般不需要修改代码。</p><h4 id="4-1-4-不小心把-MySQL-的-user-表导入到-TiDB-了，或者忘记密码，无法登录，如何处理？"><a href="#4-1-4-不小心把-MySQL-的-user-表导入到-TiDB-了，或者忘记密码，无法登录，如何处理？" class="headerlink" title="4.1.4 不小心把 MySQL 的 user 表导入到 TiDB 了，或者忘记密码，无法登录，如何处理？"></a>4.1.4 不小心把 MySQL 的 user 表导入到 TiDB 了，或者忘记密码，无法登录，如何处理？</h4><p>重启 TiDB 服务，配置文件中增加 <code>-skip-grant-table=true</code> 参数，无密码登录集群后，可以根据情况重建用户，或者重建 mysql.user 表，具体表结构搜索官网。</p><h4 id="4-1-5-在-Loader-运行的过程中，TiDB-可以对外提供服务吗？"><a href="#4-1-5-在-Loader-运行的过程中，TiDB-可以对外提供服务吗？" class="headerlink" title="4.1.5 在 Loader 运行的过程中，TiDB 可以对外提供服务吗？"></a>4.1.5 在 Loader 运行的过程中，TiDB 可以对外提供服务吗？</h4><p>该操作进行逻辑插入，TiDB 仍可对外提供服务，但不要执行相关 DDL 操作。</p><h4 id="4-1-6-如何导出-TiDB-数据？"><a href="#4-1-6-如何导出-TiDB-数据？" class="headerlink" title="4.1.6 如何导出 TiDB 数据？"></a>4.1.6 如何导出 TiDB 数据？</h4><p>TiDB 目前暂时不支持 <code>select into outfile</code>，可以通过以下方式导出 TiDB 数据：参考 <a href="https://blog.csdn.net/xin_yu_xin/article/details/7574662" target="_blank" rel="noopener">MySQL 使用 mysqldump 导出某个表的部分数据</a>，使用 mysqldump 加 where 条件导出，使用 MySQL client 将 select 的结果输出到一个文件。</p><h4 id="4-1-7-如何从-DB2、Oracle-数据库迁移到-TiDB？"><a href="#4-1-7-如何从-DB2、Oracle-数据库迁移到-TiDB？" class="headerlink" title="4.1.7 如何从 DB2、Oracle 数据库迁移到 TiDB？"></a>4.1.7 如何从 DB2、Oracle 数据库迁移到 TiDB？</h4><p>DB2、Oracle 到 TiDB 数据迁移（增量+全量），通常做法有：</p><ul><li>使用 Oracle 官方迁移工具，如 OGG、Gateway（透明网关）、CDC（Change Data Capture）。</li><li>自研数据导出导入程序实现。</li><li>导出（Spool）成文本文件，然后通过 Load infile 进行导入。</li><li>使用第三方数据迁移工具。</li></ul><p>目前看来 OGG 最为合适。</p><h4 id="4-1-8-用-Sqoop-批量写入-TiDB-数据，虽然配置了-batch-选项，但还是会遇到-java-sql-BatchUpdateExecption-statement-count-5001-exceeds-the-transaction-limitation-的错误，该如何解决？"><a href="#4-1-8-用-Sqoop-批量写入-TiDB-数据，虽然配置了-batch-选项，但还是会遇到-java-sql-BatchUpdateExecption-statement-count-5001-exceeds-the-transaction-limitation-的错误，该如何解决？" class="headerlink" title="4.1.8 用 Sqoop 批量写入 TiDB 数据，虽然配置了 --batch 选项，但还是会遇到 java.sql.BatchUpdateExecption:statement count 5001 exceeds the transaction limitation 的错误，该如何解决？"></a>4.1.8 用 Sqoop 批量写入 TiDB 数据，虽然配置了 <code>--batch</code> 选项，但还是会遇到 <code>java.sql.BatchUpdateExecption:statement count 5001 exceeds the transaction limitation</code> 的错误，该如何解决？</h4><ul><li><p>在 Sqoop 中，<code>--batch</code> 是指每个批次提交 100 条 statement，但是默认每个 statement 包含 100 条 SQL 语句，所以此时 100 * 100 = 10000 条 SQL 语句，超出了 TiDB 的事务限制 5000 条，可以增加选项 <code>-Dsqoop.export.records.per.statement=10</code> 来解决这个问题，完整的用法如下：</p><p>   copyable “shell-regular” </p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sqoop <span class="built_in">export</span> \</span><br><span class="line">    -Dsqoop.export.records.per.statement=10 \</span><br><span class="line">    --connect jdbc:mysql://mysql.example.com/sqoop \</span><br><span class="line">    --username sqoop <span class="variable">$&#123;user&#125;</span> \</span><br><span class="line">    --password <span class="variable">$&#123;passwd&#125;</span> \</span><br><span class="line">    --table <span class="variable">$&#123;tab_name&#125;</span> \</span><br><span class="line">    --<span class="built_in">export</span>-dir <span class="variable">$&#123;dir&#125;</span> \</span><br><span class="line">    --batch</span><br></pre></td></tr></table></figure></li><li><p>也可以选择增大 tidb 的单个事物语句数量限制，不过这个会导致内存上涨。</p></li></ul><h4 id="4-1-9-TiDB-有像-Oracle-那样的-Flashback-Query-功能么，DDL-支持么？"><a href="#4-1-9-TiDB-有像-Oracle-那样的-Flashback-Query-功能么，DDL-支持么？" class="headerlink" title="4.1.9 TiDB 有像 Oracle 那样的 Flashback Query 功能么，DDL 支持么？"></a>4.1.9 TiDB 有像 Oracle 那样的 Flashback Query 功能么，DDL 支持么？</h4><p>有，也支持 DDL。详细参考 <a href="/how-to/get-started/read-historical-data.md">TiDB 历史数据回溯</a>。</p><h3 id="4-2-在线数据同步"><a href="#4-2-在线数据同步" class="headerlink" title="4.2 在线数据同步"></a>4.2 在线数据同步</h3><h4 id="4-2-1-Syncer-架构"><a href="#4-2-1-Syncer-架构" class="headerlink" title="4.2.1 Syncer 架构"></a>4.2.1 Syncer 架构</h4><p>详细参考 <a href="https://pingcap.com/blog-cn/tidb-syncer/" target="_blank" rel="noopener">解析 TiDB 在线数据同步工具 Syncer</a>。</p><h5 id="4-2-1-1-Syncer-使用文档"><a href="#4-2-1-1-Syncer-使用文档" class="headerlink" title="4.2.1.1 Syncer 使用文档"></a>4.2.1.1 Syncer 使用文档</h5><p>详细参考 <a href="/reference/tools/syncer.md">Syncer 使用文档</a>。</p><h5 id="4-2-1-2-如何配置监控-Syncer-运行情况？"><a href="#4-2-1-2-如何配置监控-Syncer-运行情况？" class="headerlink" title="4.2.1.2 如何配置监控 Syncer 运行情况？"></a>4.2.1.2 如何配置监控 Syncer 运行情况？</h5><p>下载 <a href="https://github.com/pingcap/tidb-ansible/blob/master/scripts/syncer.json" target="_blank" rel="noopener">Syncer Json</a> 导入到 Grafana，修改 Prometheus 配置文件，添加以下内容：</p><ul><li>job_name: &#39;syncer_ops&#39; // 任务名字<br>  static_configs:</li><li>targets: [&#39;10.10.1.1:10096&#39;] //Syncer 监听地址与端口，通知 prometheus 拉取 Syncer 的数据。</li></ul><p>重启 Prometheus 即可。</p><h5 id="4-2-1-3-有没有现成的同步方案，可以将数据同步到-Hbase、Elasticsearh-等其他存储？"><a href="#4-2-1-3-有没有现成的同步方案，可以将数据同步到-Hbase、Elasticsearh-等其他存储？" class="headerlink" title="4.2.1.3 有没有现成的同步方案，可以将数据同步到 Hbase、Elasticsearh 等其他存储？"></a>4.2.1.3 有没有现成的同步方案，可以将数据同步到 Hbase、Elasticsearh 等其他存储？</h5><p>没有，目前依赖程序自行实现。</p><h5 id="4-2-1-4-利用-Syncer-做数据同步的时候是否支持只同步部分表？"><a href="#4-2-1-4-利用-Syncer-做数据同步的时候是否支持只同步部分表？" class="headerlink" title="4.2.1.4 利用 Syncer 做数据同步的时候是否支持只同步部分表？"></a>4.2.1.4 利用 Syncer 做数据同步的时候是否支持只同步部分表？</h5><p>支持，具体参考 Syncer 使用手册 <a href="/reference/tools/syncer.md">Syncer 使用文档</a></p><h5 id="4-2-1-5-频繁的执行-DDL-会影响-Syncer-同步速度吗？"><a href="#4-2-1-5-频繁的执行-DDL-会影响-Syncer-同步速度吗？" class="headerlink" title="4.2.1.5 频繁的执行 DDL 会影响 Syncer 同步速度吗？"></a>4.2.1.5 频繁的执行 DDL 会影响 Syncer 同步速度吗？</h5><p>频繁执行 DDL 对同步速度会有影响。对于 Sycner 来说，DDL 是串行执行的，当同步遇到了 DDL，就会以串行的方式执行，所以这种场景就会导致同步速度下降。</p><h5 id="4-2-1-6-使用-Syncer-gtid-的方式同步时，同步过程中会不断更新-syncer-meta-文件，如果-Syncer-所在的机器坏了，导致-syncer-meta-文件所在的目录丢失，该如何处理？"><a href="#4-2-1-6-使用-Syncer-gtid-的方式同步时，同步过程中会不断更新-syncer-meta-文件，如果-Syncer-所在的机器坏了，导致-syncer-meta-文件所在的目录丢失，该如何处理？" class="headerlink" title="4.2.1.6 使用 Syncer gtid 的方式同步时，同步过程中会不断更新 syncer.meta 文件，如果 Syncer 所在的机器坏了，导致 syncer.meta 文件所在的目录丢失，该如何处理？"></a>4.2.1.6 使用 Syncer gtid 的方式同步时，同步过程中会不断更新 syncer.meta 文件，如果 Syncer 所在的机器坏了，导致 syncer.meta 文件所在的目录丢失，该如何处理？</h5><p>当前 Syncer 版本的没有进行高可用设计，Syncer 目前的配置信息 syncer.meta 直接存储在硬盘上，其存储方式类似于其他 MySQL 生态工具，比如 Mydumper。因此，要解决这个问题当前可以有两个方法：</p><p>1）把 syncer.meta 数据放到比较安全的磁盘上，例如磁盘做好 raid1；</p><p>2）可以根据 Syncer 定期上报到 Prometheus 的监控信息来还原出历史同步的位置信息，该方法的位置信息在大量同步数据时由于延迟会可能不准确。</p><h5 id="4-2-1-7-Syncer-下游-TiDB-数据和-MySQL-数据不一致，DML-会退出么？"><a href="#4-2-1-7-Syncer-下游-TiDB-数据和-MySQL-数据不一致，DML-会退出么？" class="headerlink" title="4.2.1.7  Syncer 下游 TiDB 数据和 MySQL 数据不一致，DML 会退出么？"></a>4.2.1.7  Syncer 下游 TiDB 数据和 MySQL 数据不一致，DML 会退出么？</h5><ul><li>上游 MySQL 中存在数据，下游 TiDB 中该数据不存在，上游 MySQL 执行 <code>UPDATE</code> 或 <code>DELETE</code>（更新/删除）该条数据的操作时，Syncer 同步过程即不会报错退出也没有该条数据。</li><li>下游有主键索引或是唯一索引冲突时，执行 <code>UPDATE</code> 会退出，执行 <code>INSERT</code> 不会退出。</li></ul><h3 id="4-3-业务流量迁入"><a href="#4-3-业务流量迁入" class="headerlink" title="4.3 业务流量迁入"></a>4.3 业务流量迁入</h3><h4 id="4-3-1-如何快速迁移业务流量？"><a href="#4-3-1-如何快速迁移业务流量？" class="headerlink" title="4.3.1 如何快速迁移业务流量？"></a>4.3.1 如何快速迁移业务流量？</h4><p>我们建议通过 Syncer 工具搭建成多源 MySQL -&gt; TiDB 实时同步环境，读写流量可以按照需求分阶段通过修改网络配置进行流量迁移，建议 DB 上层部署一个稳定的网络 LB（HAproxy、LVS、F5、DNS 等），这样直接修改网络配置就能实现无缝流量迁移。</p><h4 id="4-3-2-TiDB-总读写流量有限制吗？"><a href="#4-3-2-TiDB-总读写流量有限制吗？" class="headerlink" title="4.3.2 TiDB 总读写流量有限制吗？"></a>4.3.2 TiDB 总读写流量有限制吗？</h4><p>TiDB 读流量可以通过增加 TiDB server 进行扩展，总读容量无限制，写流量可以通过增加 TiKV 节点进行扩容，基本上写容量也没有限制。</p><h4 id="4-3-3-Transaction-too-large-是什么原因，怎么解决？"><a href="#4-3-3-Transaction-too-large-是什么原因，怎么解决？" class="headerlink" title="4.3.3 Transaction too large 是什么原因，怎么解决？"></a>4.3.3 Transaction too large 是什么原因，怎么解决？</h4><p>TiDB 限制了单条 KV entry 不超过 6MB。</p><p>分布式事务要做两阶段提交，而且底层还需要做 Raft 复制。如果一个事务非常大，提交过程会非常慢，事务写冲突概率会增加，而且事务失败后回滚会导致不必要的性能开销。所以我们设置了 key-value entry 的总大小默认不超过 100MB。如果业务需要使用大事务，可以修改配置文件中的 <code>txn-total-size-limit</code> 配置项进行调整，最大可以修改到 10G。实际的大小限制还受机器的物理内存影响。</p><p>在 Google 的 Cloud Spanner 上面，也有类似的<a href="https://cloud.google.com/spanner/docs/limits" target="_blank" rel="noopener">限制</a>。</p><h4 id="4-3-4-如何批量导入？"><a href="#4-3-4-如何批量导入？" class="headerlink" title="4.3.4 如何批量导入？"></a>4.3.4 如何批量导入？</h4><p>导入数据的时候，可以分批插入，每批最好不要超过 1w 行。</p><h4 id="4-3-5-TiDB-中删除数据后会立即释放空间吗？"><a href="#4-3-5-TiDB-中删除数据后会立即释放空间吗？" class="headerlink" title="4.3.5 TiDB 中删除数据后会立即释放空间吗？"></a>4.3.5 TiDB 中删除数据后会立即释放空间吗？</h4><p>DELETE，TRUNCATE 和 DROP 都不会立即释放空间。对于 TRUNCATE 和 DROP 操作，在达到 TiDB 的 GC (garbage collection) 时间后（默认 10 分钟），TiDB 的 GC 机制会删除数据并释放空间。对于 DELETE 操作 TiDB 的 GC 机制会删除数据，但不会释放空间，而是当后续数据写入 RocksDB 且进行 compact 时对空间重新利用。</p><h4 id="4-3-6-Load-数据时可以对目标表执行-DDL-操作吗？"><a href="#4-3-6-Load-数据时可以对目标表执行-DDL-操作吗？" class="headerlink" title="4.3.6 Load 数据时可以对目标表执行 DDL 操作吗？"></a>4.3.6 Load 数据时可以对目标表执行 DDL 操作吗？</h4><p>不可以，加载数据期间不能对目标表执行任何 DDL 操作，这会导致数据加载失败。</p><h4 id="4-3-7-TiDB-是否支持-replace-into-语法？"><a href="#4-3-7-TiDB-是否支持-replace-into-语法？" class="headerlink" title="4.3.7 TiDB 是否支持 replace into 语法？"></a>4.3.7 TiDB 是否支持 replace into 语法？</h4><p>支持，但是 load data 不支持 replace into 语法。</p><h4 id="4-3-8-数据删除后查询速度为何会变慢？"><a href="#4-3-8-数据删除后查询速度为何会变慢？" class="headerlink" title="4.3.8 数据删除后查询速度为何会变慢？"></a>4.3.8 数据删除后查询速度为何会变慢？</h4><p>大量删除数据后，会有很多无用的 key 存在，影响查询效率。目前正在开发 Region Merge 功能，完善之后可以解决这个问题，具体看参考<a href="https://pingcap.com/blog-cn/tidb-best-practice/" target="_blank" rel="noopener">最佳实践</a>中的删除数据部分。</p><h4 id="4-3-9-数据删除最高效最快的方式？"><a href="#4-3-9-数据删除最高效最快的方式？" class="headerlink" title="4.3.9 数据删除最高效最快的方式？"></a>4.3.9 数据删除最高效最快的方式？</h4><p>在删除大量数据的时候，建议使用 <code>Delete * from t where xx limit 5000</code>（xx 建议在满足业务过滤逻辑下，尽量加上强过滤索引列或者直接使用主键选定范围，如 <code>id &gt;= 5000*n+m and id &lt;= 5000*(n+1)+m</code> 这样的方案，通过循环来删除，用 <code>Affected Rows == 0</code> 作为循环结束条件，这样避免遇到事务大小的限制。如果一次删除的数据量非常大，这种循环的方式会越来越慢，因为每次删除都是从前向后遍历，前面的删除之后，短时间内会残留不少删除标记（后续会被 GC 掉），影响后面的 Delete 语句。如果有可能，建议把 Where 条件细化。可以参考官网<a href="https://pingcap.com/blog-cn/tidb-best-practice/" target="_blank" rel="noopener">最佳实践</a>。</p><h4 id="4-3-10-TiDB-如何提高数据加载速度？"><a href="#4-3-10-TiDB-如何提高数据加载速度？" class="headerlink" title="4.3.10 TiDB 如何提高数据加载速度？"></a>4.3.10 TiDB 如何提高数据加载速度？</h4><p>主要有两个方面：</p><ul><li>目前已开发分布式导入工具 <a href="/reference/tools/tidb-lightning/overview.md">Lightning</a>，需要注意的是数据导入过程中为了性能考虑，不会执行完整的事务流程，所以没办法保证导入过程中正在导入的数据的 ACID 约束，只能保证整个导入过程结束以后导入数据的 ACID 约束。因此适用场景主要为新数据的导入（比如新的表或者新的索引），或者是全量的备份恢复（先 Truncate 原表再导入）。</li><li>TiDB 的数据加载与磁盘以及整体集群状态相关，加载数据时应关注该主机的磁盘利用率，TiClient Error/Backoff/Thread CPU 等相关 metric，可以分析相应瓶颈。</li></ul><h4 id="4-3-11-对数据做删除操作之后，空间回收比较慢，如何处理？"><a href="#4-3-11-对数据做删除操作之后，空间回收比较慢，如何处理？" class="headerlink" title="4.3.11 对数据做删除操作之后，空间回收比较慢，如何处理？"></a>4.3.11 对数据做删除操作之后，空间回收比较慢，如何处理？</h4><p>可以设置并行 GC，加快对空间的回收速度。默认并发为 1，最大可调整为 tikv 实例数量的 50%。可使用 <code>update mysql.tidb set VARIABLE_VALUE=&quot;3&quot; where VARIABLE_NAME=&quot;tikv_gc_concurrency&quot;;</code> 命令来调整。</p><h2 id="五、SQL-优化"><a href="#五、SQL-优化" class="headerlink" title="五、SQL 优化"></a>五、SQL 优化</h2><h3 id="5-1-TiDB-执行计划解读"><a href="#5-1-TiDB-执行计划解读" class="headerlink" title="5.1 TiDB 执行计划解读"></a>5.1 TiDB 执行计划解读</h3><p>详细解读 <a href="/reference/performance/understanding-the-query-execution-plan.md">理解 TiDB 执行计划</a>。</p><h4 id="5-1-1-统计信息收集"><a href="#5-1-1-统计信息收集" class="headerlink" title="5.1.1 统计信息收集"></a>5.1.1 统计信息收集</h4><p>详细解读 <a href="/reference/performance/statistics.md">统计信息</a>。</p><h4 id="5-1-2-Count-如何加速？"><a href="#5-1-2-Count-如何加速？" class="headerlink" title="5.1.2 Count 如何加速？"></a>5.1.2 Count 如何加速？</h4><p>Count 就是暴力扫表，提高并发度能显著的提升速度，修改并发度可以参考 <code>tidb_distsql_scan_concurrency</code> 变量，但是也要看 CPU 和 I/O 资源。TiDB 每次查询都要访问 TiKV，在数据量小的情况下，MySQL 都在内存里，TiDB 还需要进行一次网络访问。</p><p>提升建议：</p><ul><li>建议提升硬件配置，可以参考<a href="/how-to/deploy/hardware-recommendations.md">部署建议</a>。</li><li>提升并发度，默认是 10，可以提升到 50 试试，但是一般提升在 2-4 倍之间。</li><li>测试大数据量的 count。</li><li>调优 TiKV 配置，可以参考<a href="/reference/performance/tune-tikv.md">性能调优</a>。</li></ul><h4 id="5-1-3-查看当前-DDL-的进度？"><a href="#5-1-3-查看当前-DDL-的进度？" class="headerlink" title="5.1.3 查看当前 DDL 的进度？"></a>5.1.3 查看当前 DDL 的进度？</h4><p>通过 <code>admin show ddl</code> 查看当前 job 进度。操作如下：</p><p> copyable “sql” </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">admin <span class="keyword">show</span> <span class="keyword">ddl</span>;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">*************************** 1. row ***************************</span><br><span class="line">  SCHEMA_VER: 140</span><br><span class="line">       OWNER: 1a1c4174-0fcd-4ba0-add9-12d08c4077dc</span><br><span class="line">RUNNING_JOBS: ID:121, Type:add index, State:running, SchemaState:write reorganization, SchemaID:1, TableID:118, RowCount:77312, ArgLen:0, start time: 2018-12-05 16:26:10.652 +0800 CST, Err:&lt;nil&gt;, ErrCount:0, SnapshotVersion:404749908941733890</span><br><span class="line">     SELF_ID: 1a1c4174-0fcd-4ba0-add9-12d08c4077dc</span><br></pre></td></tr></table></figure><p>从上面操作结果可知，当前正在处理的是 <code>add index</code> 操作。且从 <code>RUNNING_JOBS</code> 列的 <code>RowCount</code> 字段可以知道当前 <code>add index</code> 操作已经添加了 77312 行索引。</p><h4 id="5-1-4-如何查看-DDL-job？"><a href="#5-1-4-如何查看-DDL-job？" class="headerlink" title="5.1.4 如何查看 DDL job？"></a>5.1.4 如何查看 DDL job？</h4><p>可以使用 <code>admin show ddl</code> 语句查看正在运行的 DDL 作业。</p><ul><li><code>admin show ddl jobs</code>：用于查看当前 DDL 作业队列中的所有结果（包括正在运行以及等待运行的任务）以及已执行完成的 DDL 作业队列中的最近十条结果。</li><li><code>admin show ddl job queries &#39;job_id&#39; [, &#39;job_id&#39;] ...</code>：用于显示 <code>job_id</code> 对应的 DDL 任务的原始 SQL 语句。此 <code>job_id</code> 只搜索正在执行中的任务以及 DDL 历史作业队列中的最近十条结果。</li></ul><h4 id="5-1-5-TiDB-是否支持基于-COST-的优化（CBO），如果支持，实现到什么程度？"><a href="#5-1-5-TiDB-是否支持基于-COST-的优化（CBO），如果支持，实现到什么程度？" class="headerlink" title="5.1.5 TiDB 是否支持基于 COST 的优化（CBO），如果支持，实现到什么程度？"></a>5.1.5 TiDB 是否支持基于 COST 的优化（CBO），如果支持，实现到什么程度？</h4><p>是的，TiDB 使用的基于成本的优化器（CBO），我们有一个小组单独会对代价模型、统计信息持续优化，除此之外，我们支持 hash join、soft merge 等关联算法。</p><h4 id="5-1-6-如何确定某张表是否需要做-analyze-？"><a href="#5-1-6-如何确定某张表是否需要做-analyze-？" class="headerlink" title="5.1.6 如何确定某张表是否需要做 analyze ？"></a>5.1.6 如何确定某张表是否需要做 analyze ？</h4><p>可以通过 <code>show stats_healthy</code> 来查看 Healthy 字段，一般小于等于 60 的表需要做 analyze。</p><h4 id="5-1-7-SQL-的执行计划展开成了树，ID-的序号有什么规律吗？这棵树的执行顺序会是怎么样的？"><a href="#5-1-7-SQL-的执行计划展开成了树，ID-的序号有什么规律吗？这棵树的执行顺序会是怎么样的？" class="headerlink" title="5.1.7 SQL 的执行计划展开成了树，ID 的序号有什么规律吗？这棵树的执行顺序会是怎么样的？"></a>5.1.7 SQL 的执行计划展开成了树，ID 的序号有什么规律吗？这棵树的执行顺序会是怎么样的？</h4><p>ID 没什么规律，只要是唯一就行，不过生成的时候，是有一个计数器，生成一个 plan 就加一，执行的顺序和序号无关，整个执行计划是一颗树，执行时从根节点开始，不断地向上返回数据。执行计划的理解，请参考<a href="/reference/performance/understanding-the-query-execution-plan.md">理解 TiDB 执行计划</a>。</p><h4 id="5-1-8-TiDB-执行计划中，task-cop-在一个-root-下，这个是并行的么？"><a href="#5-1-8-TiDB-执行计划中，task-cop-在一个-root-下，这个是并行的么？" class="headerlink" title="5.1.8 TiDB 执行计划中，task cop 在一个 root 下，这个是并行的么？"></a>5.1.8 TiDB 执行计划中，task cop 在一个 root 下，这个是并行的么？</h4><p>目前 TiDB 的计算任务隶属于两种不同的 task：cop task 和 root task。cop task 是指被下推到 KV 端分布式执行的计算任务，root task 是指在 TiDB 端单点执行的计算任务。一般来讲 root task 的输入数据是来自于 cop task 的；但是 root task 在处理数据的时候，TiKV 上的 cop task 也可以同时处理数据，等待 TiDB 的 root task 拉取，所以从这个观点上来看，他们是并行的；但是存在数据上下游关系；在执行的过程中，某些时间段其实也是并行的，第一个 cop task 在处理 [100, 200] 的数据，第二个 cop task 在处理 [1, 100] 的数据。执行计划的理解，请参考<a href="/reference/performance/understanding-the-query-execution-plan.md">理解 TiDB 执行计划</a>。</p><h2 id="六、数据库优化"><a href="#六、数据库优化" class="headerlink" title="六、数据库优化"></a>六、数据库优化</h2><h3 id="6-1-TiDB"><a href="#6-1-TiDB" class="headerlink" title="6.1 TiDB"></a>6.1 TiDB</h3><h4 id="6-1-1-TiDB-参数及调整"><a href="#6-1-1-TiDB-参数及调整" class="headerlink" title="6.1.1 TiDB 参数及调整"></a>6.1.1 TiDB 参数及调整</h4><p>详情参考 <a href="/reference/configuration/tidb-server/configuration.md">TiDB 配置参数</a>。</p><h4 id="6-1-2-如何打散热点"><a href="#6-1-2-如何打散热点" class="headerlink" title="6.1.2 如何打散热点"></a>6.1.2 如何打散热点</h4><p>TiDB 中以 Region 分片来管理数据库，通常来讲，TiDB 的热点指的是 Region 的读写访问热点。而 TiDB 中对于 PK 非整数或没有 PK 的表，可以通过设置 <code>SHARD_ROW_ID_BITS</code> 来适度分解 Region 分片，以达到打散 Region 热点的效果。详情可参考官网 <a href="/reference/configuration/tidb-server/tidb-specific-variables.md#shard_row_id_bits">TiDB 专用系统变量和语法</a>中 <code>SHARD_ROW_ID_BITS</code> 的介绍。</p><h3 id="6-2-TiKV"><a href="#6-2-TiKV" class="headerlink" title="6.2 TiKV"></a>6.2 TiKV</h3><h4 id="6-2-1-TiKV-性能参数调优"><a href="#6-2-1-TiKV-性能参数调优" class="headerlink" title="6.2.1 TiKV 性能参数调优"></a>6.2.1 TiKV 性能参数调优</h4><p>详情参考 <a href="/reference/performance/tune-tikv.md">TiKV 性能参数调优</a>。</p><h2 id="七、监控"><a href="#七、监控" class="headerlink" title="七、监控"></a>七、监控</h2><h3 id="7-1-Prometheus-监控框架"><a href="#7-1-Prometheus-监控框架" class="headerlink" title="7.1 Prometheus 监控框架"></a>7.1 Prometheus 监控框架</h3><p>详细参考 <a href="/how-to/monitor/overview.md">TiDB 监控框架概述</a>。</p><h3 id="7-2-监控指标解读"><a href="#7-2-监控指标解读" class="headerlink" title="7.2 监控指标解读"></a>7.2 监控指标解读</h3><p>详细参考 <a href="/reference/key-monitoring-metrics/overview-dashboard.md">重要监控指标详解</a>。</p><h4 id="7-2-1-目前的监控使用方式及主要监控指标，有没有更好看的监控？"><a href="#7-2-1-目前的监控使用方式及主要监控指标，有没有更好看的监控？" class="headerlink" title="7.2.1 目前的监控使用方式及主要监控指标，有没有更好看的监控？"></a>7.2.1 目前的监控使用方式及主要监控指标，有没有更好看的监控？</h4><p>TiDB 使用 Prometheus + Grafana 组成 TiDB 数据库系统的监控系统，用户在 Grafana 上通过 dashboard 可以监控到 TiDB 的各类运行指标，包括系统资源的监控指标，包括客户端连接与 SQL 运行的指标，包括内部通信和 Region 调度的指标，通过这些指标，可以让数据库管理员更好的了解到系统的运行状态，运行瓶颈等内容。在监控指标的过程中，我们按照 TiDB 不同的模块，分别列出了各个模块重要的指标项，一般用户只需要关注这些常见的指标项。具体指标请参见<a href="/reference/key-monitoring-metrics/overview-dashboard.md">官方文档</a>。</p><h4 id="7-2-2-Prometheus-监控数据默认-15-天自动清除一次，可以自己设定成-2-个月或者手动删除吗？"><a href="#7-2-2-Prometheus-监控数据默认-15-天自动清除一次，可以自己设定成-2-个月或者手动删除吗？" class="headerlink" title="7.2.2 Prometheus 监控数据默认 15 天自动清除一次，可以自己设定成 2 个月或者手动删除吗？"></a>7.2.2 Prometheus 监控数据默认 15 天自动清除一次，可以自己设定成 2 个月或者手动删除吗？</h4><p>可以的，在 Prometheus 启动的机器上，找到启动脚本，然后修改启动参数，然后重启 Prometheus 生效。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--storage.tsdb.retention&#x3D;&quot;60d&quot;</span><br></pre></td></tr></table></figure><h4 id="7-2-3-Region-Health-监控项"><a href="#7-2-3-Region-Health-监控项" class="headerlink" title="7.2.3 Region Health 监控项"></a>7.2.3 Region Health 监控项</h4><p>TiDB-2.0 版本中，PD metric 监控页面中，对 Region 健康度进行了监控，其中 Region Health 监控项是对所有 Region 副本状况的一些统计。其中 miss 是缺副本，extra 是多副本。同时也增加了按 Label 统计的隔离级别，level-1 表示这些 Region 的副本在第一级 Label 下是物理隔离的，没有配置 location label 时所有 Region 都在 level-0。</p><h4 id="7-2-4-Statement-Count-监控项中的-selectsimplefull-是什么意思？"><a href="#7-2-4-Statement-Count-监控项中的-selectsimplefull-是什么意思？" class="headerlink" title="7.2.4 Statement Count 监控项中的 selectsimplefull 是什么意思？"></a>7.2.4 Statement Count 监控项中的 selectsimplefull 是什么意思？</h4><p>代表全表扫，但是可能是很小的系统表。</p><h4 id="7-2-5-监控上的-QPS-和-Statement-OPS-有什么区别？"><a href="#7-2-5-监控上的-QPS-和-Statement-OPS-有什么区别？" class="headerlink" title="7.2.5 监控上的 QPS 和 Statement OPS 有什么区别？"></a>7.2.5 监控上的 QPS 和 Statement OPS 有什么区别？</h4><p>QPS 会统计执行的所有 SQL 命令，包括 use database、load data、begin、commit、set、show、insert、select 等。</p><p>Statement OPS 只统计 select、update、insert 等业务相关的，所以 Statement OPS 的统计和业务比较相符。</p><h2 id="八、Cloud-TiDB"><a href="#八、Cloud-TiDB" class="headerlink" title="八、Cloud TiDB"></a>八、Cloud TiDB</h2><h3 id="8-1-腾讯云"><a href="#8-1-腾讯云" class="headerlink" title="8.1 腾讯云"></a>8.1 腾讯云</h3><h4 id="8-1-1-目前-Cloud-TiDB-都有那些云厂商？"><a href="#8-1-1-目前-Cloud-TiDB-都有那些云厂商？" class="headerlink" title="8.1.1 目前 Cloud TiDB 都有那些云厂商？"></a>8.1.1 目前 Cloud TiDB 都有那些云厂商？</h4><p>Cloud TiDB 目前已经在腾讯云、UCloud 上线，都是数据库一级入口，欢迎大家使用。</p><h2 id="九、故障排除"><a href="#九、故障排除" class="headerlink" title="九、故障排除"></a>九、故障排除</h2><h3 id="9-1-TiDB-自定义报错汇总"><a href="#9-1-TiDB-自定义报错汇总" class="headerlink" title="9.1 TiDB 自定义报错汇总"></a>9.1 TiDB 自定义报错汇总</h3><h4 id="9-1-1-ERROR-8005-HY000-Write-Conflict-txnStartTS-is-stale"><a href="#9-1-1-ERROR-8005-HY000-Write-Conflict-txnStartTS-is-stale" class="headerlink" title="9.1.1 ERROR 8005 (HY000) : Write Conflict, txnStartTS is stale"></a>9.1.1 ERROR 8005 (HY000) : Write Conflict, txnStartTS is stale</h4><p>可以检查 <code>tidb_disable_txn_auto_retry</code> 是否为 on。如是，将其设置为 off；如已经是 off，将 <code>tidb_retry_limit</code> 调大到不再发生该错误。</p><h4 id="9-1-2-ERROR-9001-HY000-PD-Server-Timeout"><a href="#9-1-2-ERROR-9001-HY000-PD-Server-Timeout" class="headerlink" title="9.1.2 ERROR 9001 (HY000) : PD Server Timeout"></a>9.1.2 ERROR 9001 (HY000) : PD Server Timeout</h4><p>请求 PD 超时，请检查 PD Server 状态/监控/日志以及 TiDB Server 与 PD Server 之间的网络。</p><h4 id="9-1-3-ERROR-9002-HY000-TiKV-Server-Timeout"><a href="#9-1-3-ERROR-9002-HY000-TiKV-Server-Timeout" class="headerlink" title="9.1.3 ERROR 9002 (HY000) : TiKV Server Timeout"></a>9.1.3 ERROR 9002 (HY000) : TiKV Server Timeout</h4><p>请求 TiKV 超时，请检查 TiKV Server 状态/监控/日志以及 TiDB Server 与 TiKV Server 之间的网络。</p><h4 id="9-1-4-ERROR-9003-HY000-TiKV-Server-is-Busy"><a href="#9-1-4-ERROR-9003-HY000-TiKV-Server-is-Busy" class="headerlink" title="9.1.4 ERROR 9003 (HY000) : TiKV Server is Busy"></a>9.1.4 ERROR 9003 (HY000) : TiKV Server is Busy</h4><p>TiKV 操作繁忙，一般出现在数据库负载比较高时，请检查 TiKV Server 状态/监控/日志。</p><h4 id="9-1-5-ERROR-9004-HY000-Resolve-Lock-Timeout"><a href="#9-1-5-ERROR-9004-HY000-Resolve-Lock-Timeout" class="headerlink" title="9.1.5 ERROR 9004 (HY000) : Resolve Lock Timeout"></a>9.1.5 ERROR 9004 (HY000) : Resolve Lock Timeout</h4><p>清理锁超时，当数据库上承载的业务存在大量的事务冲突时，会遇到这种错误，请检查业务代码是否有锁争用。</p><h4 id="9-1-6-ERROR-9005-HY000-Region-is-unavailable"><a href="#9-1-6-ERROR-9005-HY000-Region-is-unavailable" class="headerlink" title="9.1.6 ERROR 9005 (HY000) : Region is unavailable"></a>9.1.6 ERROR 9005 (HY000) : Region is unavailable</h4><p>访问的 Region 不可用，某个 Raft Group 不可用，如副本数目不足，出现在 TiKV 比较繁忙或者是 TiKV 节点停机的时候，请检查 TiKV Server 状态/监控/日志。</p><h4 id="9-1-7-ERROR-9006-HY000-GC-life-time-is-shorter-than-transaction-duration"><a href="#9-1-7-ERROR-9006-HY000-GC-life-time-is-shorter-than-transaction-duration" class="headerlink" title="9.1.7 ERROR 9006 (HY000) : GC life time is shorter than transaction duration"></a>9.1.7 ERROR 9006 (HY000) : GC life time is shorter than transaction duration</h4><p><code>GC Life Time</code> 间隔时间过短，长事务本应读到的数据可能被清理了，可使用如下命令增加 <code>GC Life Time</code>：</p><p> copyable “sql” </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">update</span> mysql.tidb <span class="keyword">set</span> variable_value=<span class="string">'30m'</span> <span class="keyword">where</span> variable_name=<span class="string">'tikv_gc_life_time'</span>;</span><br></pre></td></tr></table></figure><p>其中 30m 代表仅清理 30 分钟前的数据，这可能会额外占用一定的存储空间。</p><h4 id="9-1-8-ERROR-9007-HY000-Write-Conflict"><a href="#9-1-8-ERROR-9007-HY000-Write-Conflict" class="headerlink" title="9.1.8 ERROR 9007 (HY000) : Write Conflict"></a>9.1.8 ERROR 9007 (HY000) : Write Conflict</h4><p>可以检查 <code>tidb_disable_txn_auto_retry</code> 是否为 on。如是，将其设置为 off；如已经是 off，将 <code>tidb_retry_limit</code> 调大到不再发生该错误。</p><h3 id="9-2-MySQL-原生报错汇总"><a href="#9-2-MySQL-原生报错汇总" class="headerlink" title="9.2 MySQL 原生报错汇总"></a>9.2 MySQL 原生报错汇总</h3><h4 id="9-2-1-ERROR-2013-HY000-Lost-connection-to-MySQL-server-during-query-问题的排查方法？"><a href="#9-2-1-ERROR-2013-HY000-Lost-connection-to-MySQL-server-during-query-问题的排查方法？" class="headerlink" title="9.2.1 ERROR 2013 (HY000): Lost connection to MySQL server during query 问题的排查方法？"></a>9.2.1 ERROR 2013 (HY000): Lost connection to MySQL server during query 问题的排查方法？</h4><ul><li>log 中是否有 panic</li><li>dmesg 中是否有 oom，命令：<code>dmesg -T | grep -i oom</code></li><li>长时间没有访问，也会收到这个报错，一般是 tcp 超时导致的，tcp 长时间不用, 会被操作系统 kill。</li></ul><h4 id="9-2-2-ERROR-1105-HY000-other-error-unknown-error-Wire-Error-InvalidEnumValue-4004-是什么意思？"><a href="#9-2-2-ERROR-1105-HY000-other-error-unknown-error-Wire-Error-InvalidEnumValue-4004-是什么意思？" class="headerlink" title="9.2.2 ERROR 1105 (HY000): other error: unknown error Wire Error(InvalidEnumValue(4004)) 是什么意思？"></a>9.2.2 ERROR 1105 (HY000): other error: unknown error Wire Error(InvalidEnumValue(4004)) 是什么意思？</h4><p>这类问题一般是 TiDB 和 TiKV 版本不匹配，在升级过程尽量一起升级，避免版本 mismatch。</p><h4 id="9-2-3-ERROR-1148-42000-the-used-command-is-not-allowed-with-this-TiDB-version-问题的处理方法？"><a href="#9-2-3-ERROR-1148-42000-the-used-command-is-not-allowed-with-this-TiDB-version-问题的处理方法？" class="headerlink" title="9.2.3 ERROR 1148 (42000): the used command is not allowed with this TiDB version 问题的处理方法？"></a>9.2.3 ERROR 1148 (42000): the used command is not allowed with this TiDB version 问题的处理方法？</h4><p>这个问题是因为在执行 <code>LOAD DATA LOCAL</code> 语句的时候，MySQL 客户端不允许执行此语句（即 <code>local_infile</code> 选项为 0）。解决方法是在启动 MySQL 客户端时，用 <code>--local-infile=1</code> 选项。具体启动指令类似：<code>mysql --local-infile=1 -u root -h 127.0.0.1 -P 4000</code>。有些 MySQL 客户端需要设置而有些不需要设置，原因是不同版本的 MySQL 客户端对 <code>local-infile</code> 的默认值不同。</p><h4 id="9-2-4-ERROR-9001-HY000-PD-server-timeout-start-timestamp-may-fall-behind-safe-point"><a href="#9-2-4-ERROR-9001-HY000-PD-server-timeout-start-timestamp-may-fall-behind-safe-point" class="headerlink" title="9.2.4 ERROR 9001 (HY000): PD server timeout start timestamp may fall behind safe point"></a>9.2.4 ERROR 9001 (HY000): PD server timeout start timestamp may fall behind safe point</h4><p>这个报错一般是 TiDB 访问 PD 出了问题，TiDB 后台有个 worker 会不断地从 PD 查询 safepoint，如果超过 100s 查不成功就会报这个错。一般是因为 PD 磁盘操作过忙、反应过慢，或者 TiDB 和 PD 之间的网络有问题。TiDB 常见错误码请参考<a href="/reference/error-codes.md">错误码与故障诊断</a>。</p><h3 id="9-3-TiDB-日志中的报错信息"><a href="#9-3-TiDB-日志中的报错信息" class="headerlink" title="9.3 TiDB 日志中的报错信息"></a>9.3 TiDB 日志中的报错信息</h3><h4 id="9-3-1-EOF"><a href="#9-3-1-EOF" class="headerlink" title="9.3.1 EOF"></a>9.3.1 EOF</h4><p>当客户端或者 proxy 断开连接时，TiDB 不会立刻察觉连接已断开，而是等到开始往连接返回数据时，才发现连接已断开，此时日志会打印 EOF 错误。</p>]]></content>
      
      
      <categories>
          
          <category> FAQ </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>FAQ</title>
      <link href="/2020/04/13/FAQ/"/>
      <url>/2020/04/13/FAQ/</url>
      
        <content type="html"><![CDATA[<h1 id="安装程序"><a href="#安装程序" class="headerlink" title="安装程序"></a>安装程序</h1><h2 id="装完数据库，bin下面没有disql文件是怎么回事？"><a href="#装完数据库，bin下面没有disql文件是怎么回事？" class="headerlink" title="装完数据库，bin下面没有disql文件是怎么回事？"></a>装完数据库，bin下面没有disql文件是怎么回事？</h2><blockquote><p><strong>原因：</strong><br>是因为安装的时候未选择数据库服务组件，所以只有客户端组件，不包含相关的dm命令行工具<br><strong>解决：</strong><br>1、从已经安装了达梦数据库服务组件的安装文件下复制一个bin，覆盖当前安装目录下的bin。<br>2、重新安装数据库，选择数据库服务组件</p></blockquote><h2 id="安装达梦数据库后LD-LIBRARY-PATH如何设置？"><a href="#安装达梦数据库后LD-LIBRARY-PATH如何设置？" class="headerlink" title="安装达梦数据库后LD_LIBRARY_PATH如何设置？"></a>安装达梦数据库后LD_LIBRARY_PATH如何设置？</h2><blockquote><p>当使用达梦的驱动（如unixodbc、dci、dpi、php_dm、pdo_dm等）时可能需要依赖部分达梦提供的动态链接库文件，用户需要设置系统环境变量<br>LD_LIBRARY_PATH，将达梦数据库的执行码路径添加进去，以linux上达梦默认安装位置/opt/dmdbms/bin为例：<br><code>方法一：LD_LIBRARY_PATH=$ LD_LIBRARY_PATH:/opt/dmdbms/bin 但是退出当前终端后就失效。</code><br><code>方法二：修改/.bashrc或~/.bash_profile或系统级别的/etc/profile 添加exportLD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/dmdbms/bin</code></p></blockquote><h2 id="达梦数据库的数据文件存放路径在哪？"><a href="#达梦数据库的数据文件存放路径在哪？" class="headerlink" title="达梦数据库的数据文件存放路径在哪？"></a>达梦数据库的数据文件存放路径在哪？</h2><blockquote><p>达梦数据库的数据文件存放路径是根据项目要求进行存放的，没有一个特定的路径，一般情况下，由达梦工程师进行安装部署的达梦数据库，部署后会提供一份部署文档，其中包含相应的路径信息，如果没有请参考下面方法。<br>下面简单介绍几种找到数据文件路径的方法：<br>1.询问数据库的管理和维护人员，这是他们应该了解的最基本信息之一。<br>2. 如果是Windows或有图形化界面的Linux，可以尝试通过“DM服务查看器”工具，找到DmService开头的服务，点击右键选择“属性”，在“服务属性中”的“配置文件路径”一项的路径即为数据文件路径；<br>注：如果在“DM服务查看器”中找不到相应的服务，可能服务没有注册或用其他方式进行了启动，请参考后面方法。</p><p>3.无论Window还是Linux系统，在系统中搜索“MAIN.DBF”文件，已最新的文件为准，该文件所在的目录既是数据库文件所在路径。<br>4.Linux系统，通过ps -ef|grep dmserver 命令查看进程的方式找到相应的路径。  </p><p>备注：这个达梦目录的一个说明<br>dmdbms目录：数据库安装目录。<br> bin目录：数据库核心文件目录。<br>data目录：数据库实例文件存放目录。<br>doc目录：数据库手册(安装手册，系统管理员手册，SQL语言使用手册等)存放目录。<br>drivers目录：数据库驱动存放目录。 log目录：数据库日志文件存放目录。<br>samples目录：配置文件样板（dmarch归档文件，dmmal通信文件等）存放目录。<br>tool目录：数据库工具（管理工具，数据迁移工具，审计与分析工具等）存放目录。<br>web目录：web工具（DEM）的连接及配置手册存放目录。<br>license_en：英文《软件产品授权证书》概述。<br>license_zh：中文《软件产品授权证书》概述。<br>release_en：英文达梦数据库管理系统版本号汇总。<br>release_zn：中文达梦数据库管理系统版本号汇总。<br>uninstall.exe：数据库卸载，双击即可按照提示进行数据库的卸载。</p></blockquote><h2 id="无法启动图形化，如何进行安装？"><a href="#无法启动图形化，如何进行安装？" class="headerlink" title="无法启动图形化，如何进行安装？"></a>无法启动图形化，如何进行安装？</h2><blockquote><p> /./Dminstall.bin执行报错执行错 <code>Exception in thread &quot;main&quot;java.lang.unsatisfiedLinkError: could not load SWT library. Reasons:noswt…....No such file or directory</code><br>1.<br>针对无法启动图形化的服务器或者远程方式，DM7提供纯文本安装方式。<br>安装过程如下： 1、    执行安装文件 [dmdba@RS219 test]$<br>./DMInstall.bin -i Please select the installer’s language (E/e:English<br>C/c:Chinese) [E/e]:c 解压安装程序……… 是否输入Key文件路径? (Y/y:是 N/n:否)<br>[Y/y]:n</p><p>是否设置时区? (Y/y:是 N/n:否) [Y/y]: 设置时区: [ 1]: GTM-12=日界线西 [ 2]:<br>GTM-11=萨摩亚群岛 [ 3]: GTM-10=夏威夷 [ 4]: GTM-09=阿拉斯加 [ 5]:<br>GTM-08=太平洋时间（美国和加拿大） [ 6]: GTM-07=亚利桑那 [ 7]: GTM-06=中部时间（美国和加拿大） [ 8]:<br>GTM-05=东部部时间（美国和加拿大） [ 9]: GTM-04=大西洋时间（美国和加拿大） [10]: GTM-03=巴西利亚<br>[11]: GTM-02=中大西洋 [12]: GTM-01=亚速尔群岛 [13]: GTM=格林威治标准时间 [14]:<br>GTM+01=萨拉热窝 [15]: GTM+02=开罗 [16]: GTM+03=莫斯科 [17]: GTM+04=阿布扎比 [18]:<br>GTM+05=伊斯兰堡 [19]: GTM+06=达卡 [20]: GTM+07=曼谷，河内 [21]: GTM+08=中国标准时间<br>[22]: GTM+09=汉城 [23]: GTM+10=关岛 [24]: GTM+11=所罗门群岛 [25]: GTM+12=斐济<br>[26]: GTM+13=努库阿勒法 [27]: GTM+14=基里巴斯 请选择设置时区 [9]:21 安装类型: 1 典型安装 2 服务器<br>3 客户端 4 自定义 请选择安装类型的数字序号 [1 典型安装]:1 所需空间: 828M</p><p>请选择安装目录 [/home/dmdba/dmdbms]:/home/dmdba/dmdbms 可用空间: 13T<br>是否确认安装路径(/home/dmdba/dmdbms)? (Y/y:是 N/n:否)  [Y/y]:y</p><p>安装前小结 安装位置: /data/dmdata 所需空间: 828M 可用空间: 13T 版本信息:  有效日期:  安装类型: 典型安装<br>是否确认安装? (Y/y:是 N/n:否):y 2019-07-28 22:04:37  [INFO] 安装 default 模块…<br>2019-07-28 22:04:37  [INFO] 安装达梦数据库… 2019-07-28 22:04:39  [INFO] 安装<br>server 模块… 2019-07-28 22:04:39  [INFO] 安装 client 模块… 2019-07-28<br>22:04:39  [INFO] 安装 drivers 模块… 2019-07-28 22:04:39  [INFO] 安装<br>manual 模块… 2019-07-28 22:04:39  [INFO] 安装 service 模块… 2019-07-28<br>22:04:41  [INFO] 移动ant日志文件。 2019-07-28 22:04:41  [INFO] 安装达梦数据库完成。</p><p>请以root系统用户执行命令: /home/dmdba/script/root/root_installer.sh</p><p>安装结束</p><p>2、    用root执行root_installer.sh脚本，数据库安装即可完成  [root@RS219 test]#<br>/home/dmdba/script/root/root_installer.sh 移动<br>/home/dmdba/bin/dm_svc.conf 到/etc目录 修改服务器权限 创建DmAPService服务<br>创建服务(DmAPService)完成 启动DmAPService服务</p><p>2:<br>针对无法启动图形化的服务器，DM7提供了dminit通过命令行初始化实例。系统管理员可以利用该工具提供的各种参数，设置数据库存放路径、段页大小、是否对大小写敏感以及是否使用<br>unicode，创建出满足用户需要的初始数据库。该工具位于安装目录的 bin\目录下，举例如下： [dmdba@ ~]# cd<br>/opt/dmdbms/bin [dmdba@ ~]# ./dminit path=/opt/dmdbms/data<br>注：该工具的详细介绍及使用办法请详细参考《DM7系统管理员手册》7.3章节。</p></blockquote><h2 id="windows达梦数据库卸载不完全，重新装达梦数据库现有服务失败-该实例名已被其他实例占用"><a href="#windows达梦数据库卸载不完全，重新装达梦数据库现有服务失败-该实例名已被其他实例占用" class="headerlink" title="windows达梦数据库卸载不完全，重新装达梦数据库现有服务失败/该实例名已被其他实例占用  "></a>windows达梦数据库卸载不完全，重新装达梦数据库现有服务失败/该实例名已被其他实例占用  </h2><blockquote><p>1：卸载默认不会删除数据库DATA 这是为了保护数据 确定以前的所有数据不要的话才可以删除<br>2：系统的服务管理器里里查看是否有DMserviceDMSERVER<br>3：以管理员开启CMD 然后执行：sc delete “服务名” 如： sc delete DmServiceDMSERVER</p></blockquote><h2 id="启动-重启达梦数据库-失败"><a href="#启动-重启达梦数据库-失败" class="headerlink" title="启动/重启达梦数据库 失败 "></a>启动/重启达梦数据库 失败 </h2><blockquote><p>1：启动失败： 用户可能没有初始化，需要初始化数据库  <a href="http://bbs.dameng.com/forum.php?mod=viewthread&amp;tid=136435&amp;extra=page%3D2" target="_blank" rel="noopener">http://bbs.dameng.com/forum.php?mod=viewthread&amp;tid=136435&amp;extra=page%3D2</a><br>2：参考达梦系统管理员手册，第7章 启动和关闭数据库 ，看是否启动方式错误。 或者可以参考如下链接：<br><a href="https://www.cndba.cn/dave/article/3566" target="_blank" rel="noopener">https://www.cndba.cn/dave/article/3566</a>    3：如下信息来自于达梦数据技术工程，希望也有帮助<br><a href="http://bbs.dameng.com/forum.php?mod=viewthread&amp;tid=44811&amp;extra=page%3D5%26filter%3Dauthor%26orderby%3Ddateline" target="_blank" rel="noopener">http://bbs.dameng.com/forum.php?mod=viewthread&amp;tid=44811&amp;extra=page%3D5%26filter%3Dauthor%26orderby%3Ddateline</a></p></blockquote><h2 id="数据库的页大小，只能通过重新实例化数据库进行修改吗-都有什么参数是事先需要确定好的？"><a href="#数据库的页大小，只能通过重新实例化数据库进行修改吗-都有什么参数是事先需要确定好的？" class="headerlink" title="数据库的页大小，只能通过重新实例化数据库进行修改吗?都有什么参数是事先需要确定好的？"></a>数据库的页大小，只能通过重新实例化数据库进行修改吗?都有什么参数是事先需要确定好的？</h2><blockquote><p>是的，数据库的页大小只能通过重新初始化实例来进行修改。<br>需要事先确定好的参数有字符集，页簇的大小，这些参数配置一定要安装前确认好，以免安装后不能修改造成不必要的麻烦。</p></blockquote><h2 id="簇大小和页大小的设置都会影响什么"><a href="#簇大小和页大小的设置都会影响什么" class="headerlink" title="簇大小和页大小的设置都会影响什么?"></a>簇大小和页大小的设置都会影响什么?</h2><blockquote><p>簇是数据页的上级逻辑单元 ，由同一个数据文件中 16 个或 32个连续的数据页组成。<br>在DM数据库中，簇的大小由用户在创建数据库时指定，默认大小为16。假定某个数据文件 大小为 32MB，页大小为 8KB，则共有<br>32MB/8KB/16=256 个簇，每个簇的大小为<br>8K*16=128K。和数据页的大小一样，一旦创建好数据库，此后该数据库的簇的大小就不能 够改变。 数据页（也称数据块）是 DM<br>数据库中最小的数据存储单元。页的大小对应物理存储空 间上特定数量的存储字节，在 DM 数据库中，页大小可以为 4KB、8KB、16KB或者<br>32KB， 用户在创建数据库时可以指定，默认大小为8KB，一旦创建好了数据库，则在该库的整个生 命周期内，页大小都不能够改变。</p></blockquote><h2 id="是不是每次重启之后达梦数据库就直接自动启动了不用执行什么脚本了？"><a href="#是不是每次重启之后达梦数据库就直接自动启动了不用执行什么脚本了？" class="headerlink" title="是不是每次重启之后达梦数据库就直接自动启动了不用执行什么脚本了？"></a>是不是每次重启之后达梦数据库就直接自动启动了不用执行什么脚本了？</h2><blockquote><ol><li>如果是图形化的方式创建实例：图形化工具会自动创建开启自启服务，所以不需要再进行其他操作就可以让实例开机自启。</li><li>如果是命令行的方式创建实例：需要自己手动注册开机自启的服务，注册自启服务之后，可以实现开机自启。如果没有注册开机自启服务，则不会实现实例的开机自启功能。</li></ol></blockquote><h2 id="安装时提示写入权限不够的问题怎么解决？"><a href="#安装时提示写入权限不够的问题怎么解决？" class="headerlink" title="安装时提示写入权限不够的问题怎么解决？"></a>安装时提示写入权限不够的问题怎么解决？</h2><blockquote><p>提示写入权限不足，则是操作系统层面的权限不足的问题。</p><ol><li>先知道自己是使用哪个用户进行安装达梦数据库。</li><li>然后查看相应的安装目录下是否有对应用户的权限，一般的root用户对应的目录是/opt/dmdbms；dmdba用户对应的目录是/home/dmdba/dmdbms。</li><li>将对应目录的权限使用chmod命令授权给相应的用户。</li></ol></blockquote><h2 id="centos7-6-1810的Docker容器里面以静默方式安装DM7最后一步报错了，提示Openation-not-Permitted"><a href="#centos7-6-1810的Docker容器里面以静默方式安装DM7最后一步报错了，提示Openation-not-Permitted" class="headerlink" title="centos7.6.1810的Docker容器里面以静默方式安装DM7最后一步报错了，提示Openation not Permitted"></a>centos7.6.1810的Docker容器里面以静默方式安装DM7最后一步报错了，提示Openation not Permitted</h2><blockquote><p>docker添加privileged启动参数就好了</p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/04/13/hello-world/"/>
      <url>/2020/04/13/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
